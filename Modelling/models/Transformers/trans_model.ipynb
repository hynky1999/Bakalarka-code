{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: datasets in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (4.25.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (58.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: packaging in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pandas in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: xxhash in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: multiprocess in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (1.24.1)\n",
      "Requirement already satisfied: dill<0.3.7 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/lnet/aic/personal/kydliceh/non_runable/NLP_venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch.nn as nn\n",
    "def grad_params(params, freeze=True):\n",
    "    for param in params:\n",
    "        param.requires_grad = freeze\n",
    "\n",
    "\n",
    "\n",
    "def get_model(out_dim=5, freeze_layers=2):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"ufal/robeczech-base\", num_labels=out_dim)\n",
    "    grad_params(model.parameters(), freeze=True)\n",
    "    grad_params(model.classifier.parameters(), freeze=False)\n",
    "    for layer in model.roberta.encoder.layer[-freeze_layers:]:\n",
    "        grad_params(layer.parameters(), freeze=False)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dataset (/home/kydliceh/.cache/huggingface/datasets/dataset/default/0.0.0/3a21ebffd6f7380b097ffe2f8be2beda23497fd4b6ff06de19b9c473635bb199)\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = load_dataset(\"../../../final_dataset/dataset.py\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dataset (/home/kydliceh/.cache/huggingface/datasets/dataset/default/0.0.0/3a21ebffd6f7380b097ffe2f8be2beda23497fd4b6ff06de19b9c473635bb199)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"../../../final_dataset/dataset.py\", split=\"train\")\n",
    "train_dataset = train_dataset.remove_columns([\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2449b2b1e24fbf95965ca92ce60183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1784 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\")\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, max_length=512)\n",
    "\n",
    "train_dataset_new = train_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad3ba628a284533a37a0c33040cb855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.remove_columns([\"category\"])\n",
    "eval_dataset_new = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(max_length=512, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(x, column):\n",
    "    x = x.filter(lambda ex: ex[column] is not None)\n",
    "    x = x.rename_column(column, \"labels\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c443f2bbfb974d07be0f75cafa67b2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1784 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "server_dataset = prepare_dataset(train_dataset_new, \"server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0327611c02a148e3b968c274eedee152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "server_eval_dataset = prepare_dataset(eval_dataset_new, \"server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from transformers import TrainingArguments, Trainer\n",
    "def train_classification(name: str, model, dataset, eval_dataset, epochs=2, batch_size=10):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    training_args = TrainingArguments(output_dir=f\"./{name}\", overwrite_output_dir=True, num_train_epochs=2, per_gpu_train_batch_size=batch_size, per_gpu_eval_batch_size=batch_size,\n",
    "    logging_dir=f\"./logs/{name}\", logging_steps=1000, save_steps=10000, save_total_limit=5, evaluation_strategy=\"steps\", eval_steps=10000, learning_rate=2e-5, warmup_steps=100, weight_decay=0.05, adam_beta1=0.9, adam_beta2=0.999, warmup_ratio=0.1)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda x: {\"accuracy\": (x.predictions.argmax(-1) == x.label_ids).mean()},\n",
    "    )\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(6)\n",
    "train_classification(\"server\", model, server_dataset, server_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kydliceh/.cache/huggingface/datasets/dataset/default/0.0.0/3a21ebffd6f7380b097ffe2f8be2beda23497fd4b6ff06de19b9c473635bb199/cache-3584e9292ab6e185.arrow\n",
      "Loading cached processed dataset at /home/kydliceh/.cache/huggingface/datasets/dataset/default/0.0.0/3a21ebffd6f7380b097ffe2f8be2beda23497fd4b6ff06de19b9c473635bb199/cache-d237c5eda9ff5747.arrow\n"
     ]
    }
   ],
   "source": [
    "day_of_week_dataset = prepare_dataset(train_dataset_new, \"day_of_week\")\n",
    "day_of_week_eval_dataset = prepare_dataset(eval_dataset_new, \"day_of_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_day \u001b[39m=\u001b[39m get_model(\u001b[39m7\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_classification(\u001b[39m\"\u001b[39m\u001b[39mday_of_week\u001b[39m\u001b[39m\"\u001b[39m, model, server_dataset, server_eval_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_day = get_model(7)\n",
    "train_classification(\"day_of_week\", model_day, day_of_week_dataset, day_of_week_eval_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ef6dd07bac4272f716e725ea8b79349a1e1a5da9c3680ee7af3d80a9646d624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
