{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ufal/robeczech-base\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_head.decoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import Callback\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall, ConfusionMatrix, Metric\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MetricStruct:\n",
    "    readable_name: str\n",
    "    metric: Metric\n",
    "    step: bool\n",
    "    epoch: bool\n",
    "\n",
    "\n",
    "class TrainMetricCallback(Callback):\n",
    "    def __init__(self, metric: MetricStruct):\n",
    "        super().__init__()\n",
    "        self.metric = metric\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module) -> None:\n",
    "        if self.metric.epoch:\n",
    "            epoch_value = self.metric.metric.compute()\n",
    "            trainer.logger.log_metrics({f\"train/{self.metric.readable_name}\": epoch_value}, step=trainer.global_step)\n",
    "        self.metric.metric.reset()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx) -> None:\n",
    "        labels = batch['labels']\n",
    "        if not isinstance(outputs, dict) or 'logits' not in outputs:\n",
    "            raise ValueError('The `outputs` should be a dict with key `logits`.')\n",
    "        preds = outputs['logits'].argmax(dim=1)\n",
    "        if self.metric.step:\n",
    "            step_value = self.metric.metric(preds, labels)\n",
    "            trainer.logger.log_metrics({f\"train/{self.metric.readable_name}\": step_value}, step=trainer.global_step)\n",
    "        if self.metric.epoch:\n",
    "            self.metric.metric.update(preds, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import BaseFinetuning\n",
    "\n",
    "class SimpleLayersFreezer(BaseFinetuning):\n",
    "    def __init__(self, last_unfreeze_layers: int):\n",
    "        super().__init__()\n",
    "        self.last_unfreeze_layers = last_unfreeze_layers\n",
    "\n",
    "    def finetune_function(\n",
    "        self, pl_module: \"pl.LightningModule\", epoch: int, optimizer, opt_idx: int\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def freeze_before_training(self, model):\n",
    "        self.freeze(model)\n",
    "        # Classifier unfreeze\n",
    "        if hasattr(model.pretrained_model, \"classifier\"):\n",
    "            self.make_trainable(model.pretrained_model.classifier)\n",
    "        # Last freeze_layers layers unfreeze\n",
    "        if hasattr(model.pretrained_model, 'roberta') and hasattr(model.pretrained_model.roberta, 'encoder'):\n",
    "            self.make_trainable(model.pretrained_model.roberta.encoder.layer[-self.last_unfreeze_layers:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from lightning import LightningModule \n",
    "import torch\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from transformers import AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall, ConfusionMatrix, Metric\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MetricStruct:\n",
    "    readable_name: str\n",
    "    metric: Metric\n",
    "    step: bool\n",
    "    epoch: bool\n",
    "    \n",
    "\n",
    "def prepare_confussion_matrix_for_logging(confusion_matrix, class_names):\n",
    "    data = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            data.append((\n",
    "                class_names[i],\n",
    "                class_names[j],\n",
    "                confusion_matrix[i, j]\n",
    "            ))\n",
    "    return data, [\"Actual\", \"Predicted\", \"Count\"]\n",
    "\n",
    "class FineTunedRobeCzech(LightningModule):\n",
    "    def __init__(self, model_chp, class_names, train_metrics: List[MetricStruct], val_metrics: List[MetricStruct], test_metrics: List[MetricStruct], lr=2e-5, warmup_steps=1000, betas=(0.9, 0.98), eps=1e-08, weight_decay=0.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.pretrained_model = self.get_model(model_chp, len(class_names))\n",
    "        self.metrics = {\n",
    "            \"train\": train_metrics,\n",
    "            \"val\": val_metrics,\n",
    "            \"test\": test_metrics\n",
    "        }\n",
    "\n",
    "    def get_model(self, model_chp, num_dim):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_chp, num_labels=num_dim)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def log_metrics(self, output: SequenceClassifierOutput, labels, split):\n",
    "        predicted_labels = torch.argmax(output.logits, dim=1)\n",
    "        self.log(f\"{split}/loss\", output.loss, logger=True, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        for metric_struct in self.metrics[split]:\n",
    "            if metric_struct.step:\n",
    "                step_value = metric_struct.metric(predicted_labels, labels)\n",
    "                self.log(f\"{split}/{metric_struct.readable_name}_step\", step_value, logger=True)\n",
    "            else:\n",
    "                metric_struct.metric.update(predicted_labels, labels)\n",
    "\n",
    "    def log_confussion_matrix(self, cfs_matrix, split):\n",
    "        if not isinstance(self.logger, WandbLogger):\n",
    "            raise Exception(\"Confusion matrix logging is only supported for wandb logger\")\n",
    "        data, cols = prepare_confussion_matrix_for_logging(cfs_matrix, self.hparams.class_names)\n",
    "        self.logger.log_table(f\"{split}/confusion_matrix_{self.current_epoch}\", data=data, columns=cols)\n",
    "\n",
    "\n",
    "    def reset_and_log_metrics(self, split):\n",
    "        for metric_struct in self.metrics[split]:\n",
    "            if metric_struct.epoch:\n",
    "                if isinstance(metric_struct.metric, MulticlassConfusionMatrix):\n",
    "                    cm = metric_struct.metric.compute()\n",
    "                    self.log_confussion_matrix(cm, split)\n",
    "                else:\n",
    "                    self.log(f\"{split}/{metric_struct.readable_name}_epoch\", metric_struct.metric.compute(), logger=True)\n",
    "            metric_struct.metric.reset()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self.pretrained_model(**batch)\n",
    "        self.log_metrics(output, batch[\"labels\"], \"train\")\n",
    "        return output.loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.reset_and_log_metrics(\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self.pretrained_model(**batch)\n",
    "        labels = batch[\"labels\"]\n",
    "        self.log_metrics(output, labels, \"val\")\n",
    "        return output.loss\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.reset_and_log_metrics(\"val\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        output = self.pretrained_model(**batch)\n",
    "        labels = batch[\"labels\"]\n",
    "        self.log_metrics(output, labels ,\"test\")\n",
    "        return output.loss\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        self.reset_and_log_metrics(\"test\")\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        scheduler = None\n",
    "        # Use hugging face settings\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.pretrained_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.pretrained_model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.hparams.lr, eps=self.hparams.eps, betas=self.hparams.betas )\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.warmup_steps,\n",
    "            num_training_steps=self.trainer.estimated_stepping_batches,\n",
    "        )\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train split\n",
      "Preparing validation split\n",
      "Preparing test split\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerBase, AutoTokenizer, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from pathlib import Path\n",
    "from lightning.pytorch import LightningDataModule\n",
    "import shutil\n",
    "\n",
    "class NewsDataModule(LightningDataModule):\n",
    "    def __init__(self, column, tokenizer, max_length=512, batch_size=12, num_proc=4, trunc_type=\"start\", cache_dir=Path(\"cache/czech_news_proc\"), reload_cache=False):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_proc = num_proc\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer, use_fast=True)\n",
    "        self.max_length = max_length\n",
    "        self.column = column\n",
    "        self.trunc_type = trunc_type\n",
    "        self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer, padding=True)\n",
    "        self.cache_dir = cache_dir\n",
    "        self.reload_cache = reload_cache\n",
    "\n",
    "        \n",
    "\n",
    "    def prepare_split(self, split, reload_cache):\n",
    "        print(f\"Preparing {split} split\")\n",
    "        split_cache_dir = self.cache_dir / str(self.max_length) / split\n",
    "        if split_cache_dir.exists():\n",
    "            if not reload_cache:\n",
    "                return\n",
    "            else:\n",
    "                shutil.rmtree(split_cache_dir)\n",
    "                split_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        dataset = load_dataset(str(\"hynky/czech_news_dataset\"), split=split)\n",
    "        dataset = dataset.rename_column(self.column, \"labels\")\n",
    "        cols = {\"labels\", \"attention_mask\", \"input_ids\"}\n",
    "        dataset = dataset.map(lambda batch: self.tokenizer(batch[\"content\"], truncation=True, max_length=self.max_length), keep_in_memory=True, batched=True)\n",
    "        # Remove \"Nones\"\n",
    "        dataset = dataset.map(\n",
    "            lambda batch: {\"labels\": [x - 1 for x in batch[\"labels\"] if x != 0]}, batched=True, num_proc=self.num_proc,\n",
    "            keep_in_memory=True,\n",
    "        )\n",
    "        dataset = dataset.remove_columns(set(dataset.column_names) - cols)\n",
    "        dataset.set_format(\"pt\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "        print(\"Saving\")\n",
    "        dataset.save_to_disk(str(split_cache_dir), num_proc=self.num_proc)\n",
    "\n",
    "    def load_split(self, split):\n",
    "        return load_from_disk(self.cache_dir / str(self.max_length) / split)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.prepare_split(\"train\", reload_cache=self.reload_cache)\n",
    "        self.prepare_split(\"validation\", reload_cache=self.reload_cache)\n",
    "        self.prepare_split(\"test\", reload_cache=self.reload_cache)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = self.load_split(\"train\")\n",
    "            self.val_dataset = self.load_split(\"validation\")\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = self.load_split(\"test\")\n",
    "            \n",
    "\n",
    "    def create_dataloader(self, dataset):\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_proc, collate_fn=self.data_collator, shuffle=True)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.train_dataset)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.val_dataset)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.test_dataset)\n",
    "\n",
    "data_module = NewsDataModule(\"server\", \"ufal/robeczech-base\", reload_cache=False)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import DeviceStatsMonitor, LearningRateMonitor, ModelCheckpoint, Timer, EarlyStopping\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "column = \"server\"\n",
    "logger = WandbLogger(project=f\"{column}_NN\",log_model=True)\n",
    "class_names = data_module.train_dataset.features[\"labels\"].names[1:]\n",
    "\n",
    "train_metrics, test_metrics, val_metrics =[[\n",
    "    MetricStruct(\"accuracy\", Accuracy(task=\"multiclass\", num_classes=len(class_names)), step=False, epoch=True),\n",
    "    MetricStruct(\"f1_macro\", F1Score(task=\"multiclass\", num_classes=len(class_names), average=\"macro\"), step=True, epoch=True),\n",
    "    MetricStruct(\"f1_micro\",  F1Score(task=\"multiclass\", num_classes=len(class_names), average=\"micro\"), step=True, epoch=True),\n",
    "    MetricStruct(\"precission\", Precision(task=\"multiclass\", num_classes=len(class_names), average=\"macro\"), step=False, epoch=True),\n",
    "    MetricStruct(\"recall\", Recall(task=\"multiclass\", num_classes=len(class_names), average=\"macro\"), step=False, epoch=True),\n",
    "    MetricStruct(\"confusion_matrix\", ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names)), step=False, epoch=True),\n",
    "] for _ in range(3)]\n",
    "\n",
    "model = FineTunedRobeCzech(\"ufal/robeczech-base\", class_names, train_metrics=train_metrics, test_metrics=test_metrics, val_metrics=val_metrics)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "    max_epochs=4,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        SimpleLayersFreezer(2),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        EarlyStopping(monitor=\"val/loss\", patience=3, mode=\"min\"),\n",
    "        ModelCheckpoint(monitor=\"val/loss\", save_top_k=5, mode=\"min\"),\n",
    "        Timer(),\n",
    "    ],\n",
    "    enable_model_summary=True,\n",
    "    enable_progress_bar=True,\n",
    "    logger=logger,\n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    "    limit_test_batches=1,\n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval=1,\n",
    ")\n",
    "\n",
    "#trainer.fit(model, datamodule=data_module)\n",
    "# trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train split\n",
      "Preparing validation split\n",
      "Preparing test split\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">lightning.pytorch.tuner.tuning</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> Tuner                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>tuner = Tuner(trainer)                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>4 tuner.lr_find(model, datamodule=data_module)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tuner/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tuning.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">267</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">lr_find</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   │   </span>lr_finder_callback._early_exit = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks = [lr_finder_callback] + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>267 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">268 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">269 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks = [cb <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> cb <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> cb <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> lr_fi   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">270 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">608</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 605 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 606 │   │   </span>model = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_unwrap_optimized(model)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 607 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 608 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 609 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 610 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 611 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">38</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>38 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> _TunerExitException:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41 │   │   </span>trainer._call_teardown_hook()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">650</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_fit_impl</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 647 │   │   │   </span>model_provided=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 648 │   │   │   </span>model_connected=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lightning_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 649 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 650 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run(model, ckpt_path=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ckpt_path)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 651 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 652 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.stopped                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 653 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1048</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1045 │   │   # SET UP TRAINING</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1047 │   │   </span>log.detail(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}: setting up strategy environment\"</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1048 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy.setup_environment()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1049 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.__setup_profiler()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1050 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1051 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_setup_hook()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># allow user to setup lightning_module in accelerator e</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strategies/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">strategy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup_environment</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">environment before setup is complete.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.setup_device(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.root_device)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup_optimizers</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trainer: <span style=\"color: #808000; text-decoration-color: #808000\">\"pl.Trainer\"</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Creates optimizers and schedulers.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">accelerators/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">cuda.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">43</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup_device</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> device.type != <span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> MisconfigurationException(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Device should be GPU, got {</span>device<span style=\"color: #808000; text-decoration-color: #808000\">} instead</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 43 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_check_cuda_matmul_precision(device)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 │   │   </span>torch.cuda.set_device(device)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trainer: <span style=\"color: #808000; text-decoration-color: #808000\">\"pl.Trainer\"</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/fabric/a</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ccelerators/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">cuda.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">246</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_cuda_matmul_precision</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _TORCH_GREATER_EQUAL_1_12:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244 │   │   # before 1.12, tf32 was used by default</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">245 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>246 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>major, _ = torch.cuda.get_device_capability(device)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">247 │   </span>ampere_or_later = major &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Ampere and later leverage tensor cores, where this s</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> ampere_or_later:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">357</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_device_capability</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">354 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">355 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tuple(int, int): the major and minor cuda capability of the device</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>357 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>prop = get_device_properties(device)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">358 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> prop.major, prop.minor                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">359 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">371</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_device_properties</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">369 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">_CudaDeviceProperties: the properties of the device</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">370 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>371 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_lazy_init()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># will define _get_device_properties</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">372 │   </span>device = _get_device_index(device, optional=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">373 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> device &lt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> device &gt;= device_count():                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">374 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AssertionError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Invalid device id\"</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">229</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_lazy_init</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 │   │   # are found or any other error occurs</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'CUDA_MODULE_LOADING'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> os.environ:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 │   │   │   </span>os.environ[<span style=\"color: #808000; text-decoration-color: #808000\">'CUDA_MODULE_LOADING'</span>] = <span style=\"color: #808000; text-decoration-color: #808000\">'LAZY'</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>229 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch._C._cuda_init()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 │   │   # Some of the queued calls may reentrantly call _lazy_init();</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 │   │   # we need to just return without initializing in that case.</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">232 │   │   # However, we must not let any *other* threads in!</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA driver initialization failed, you might not have a CUDA gpu.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mlightning\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mpytorch\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtuner\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtuning\u001b[0m \u001b[94mimport\u001b[0m Tuner                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mtuner = Tuner(trainer)                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4 tuner.lr_find(model, datamodule=data_module)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtuner/\u001b[0m\u001b[1;33mtuning.py\u001b[0m:\u001b[94m267\u001b[0m in \u001b[92mlr_find\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   \u001b[0mlr_finder_callback._early_exit = \u001b[94mTrue\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.callbacks = [lr_finder_callback] + \u001b[96mself\u001b[0m.trainer.callbacks             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m267 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m268 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m269 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.callbacks = [cb \u001b[94mfor\u001b[0m cb \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.trainer.callbacks \u001b[94mif\u001b[0m cb \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m lr_fi   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m270 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m608\u001b[0m in \u001b[92mfit\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 605 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 606 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = \u001b[96mself\u001b[0m._maybe_unwrap_optimized(model)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 607 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 608 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 609 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 610 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 611 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m38\u001b[0m in \u001b[92m_call_and_handle_interrupt\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m38 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m _TunerExitException:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m41 \u001b[0m\u001b[2m│   │   \u001b[0mtrainer._call_teardown_hook()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m650\u001b[0m in \u001b[92m_fit_impl\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 647 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_provided=\u001b[94mTrue\u001b[0m,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 648 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_connected=\u001b[96mself\u001b[0m.lightning_module \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 649 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 650 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._run(model, ckpt_path=\u001b[96mself\u001b[0m.ckpt_path)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 651 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 652 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.state.stopped                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 653 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training = \u001b[94mFalse\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1048\u001b[0m in \u001b[92m_run\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1045 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# SET UP TRAINING\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1046 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1047 \u001b[0m\u001b[2m│   │   \u001b[0mlog.detail(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m: setting up strategy environment\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1048 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy.setup_environment()                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1049 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.__setup_profiler()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1050 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1051 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._call_setup_hook()  \u001b[2m# allow user to setup lightning_module in accelerator e\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mstrategies/\u001b[0m\u001b[1;33mstrategy.py\u001b[0m:\u001b[94m131\u001b[0m in \u001b[92msetup_environment\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33menvironment before setup is complete.\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.accelerator \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m131 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.setup_device(\u001b[96mself\u001b[0m.root_device)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup_optimizers\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Creates optimizers and schedulers.\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33maccelerators/\u001b[0m\u001b[1;33mcuda.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92msetup_device\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m MisconfigurationException(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mDevice should be GPU, got \u001b[0m\u001b[33m{\u001b[0mdevice\u001b[33m}\u001b[0m\u001b[33m instead\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 43 \u001b[2m│   │   \u001b[0m_check_cuda_matmul_precision(device)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   \u001b[0mtorch.cuda.set_device(device)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/fabric/a\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mccelerators/\u001b[0m\u001b[1;33mcuda.py\u001b[0m:\u001b[94m246\u001b[0m in \u001b[92m_check_cuda_matmul_precision\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m243 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m _TORCH_GREATER_EQUAL_1_12:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m244 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# before 1.12, tf32 was used by default\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m245 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m246 \u001b[2m│   \u001b[0mmajor, _ = torch.cuda.get_device_capability(device)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   \u001b[0mampere_or_later = major >= \u001b[94m8\u001b[0m  \u001b[2m# Ampere and later leverage tensor cores, where this s\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m ampere_or_later:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/\u001b[0m\u001b[1;33m__init_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m_.py\u001b[0m:\u001b[94m357\u001b[0m in \u001b[92mget_device_capability\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m354 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m355 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mtuple(int, int): the major and minor cuda capability of the device\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m357 \u001b[2m│   \u001b[0mprop = get_device_properties(device)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m prop.major, prop.minor                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m359 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m360 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/\u001b[0m\u001b[1;33m__init_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m_.py\u001b[0m:\u001b[94m371\u001b[0m in \u001b[92mget_device_properties\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m_CudaDeviceProperties: the properties of the device\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m370 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m371 \u001b[2m│   \u001b[0m_lazy_init()  \u001b[2m# will define _get_device_properties\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device, optional=\u001b[94mTrue\u001b[0m)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device < \u001b[94m0\u001b[0m \u001b[95mor\u001b[0m device >= device_count():                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m374 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAssertionError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mInvalid device id\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/\u001b[0m\u001b[1;33m__init_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m_.py\u001b[0m:\u001b[94m229\u001b[0m in \u001b[92m_lazy_init\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# are found or any other error occurs\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mCUDA_MODULE_LOADING\u001b[0m\u001b[33m'\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m os.environ:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2m│   │   │   \u001b[0mos.environ[\u001b[33m'\u001b[0m\u001b[33mCUDA_MODULE_LOADING\u001b[0m\u001b[33m'\u001b[0m] = \u001b[33m'\u001b[0m\u001b[33mLAZY\u001b[0m\u001b[33m'\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m229 \u001b[2m│   │   \u001b[0mtorch._C._cuda_init()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# we need to just return without initializing in that case.\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m232 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# However, we must not let any *other* threads in!\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCUDA driver initialization failed, you might not have a CUDA gpu.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.tuner.tuning import Tuner\n",
    "\n",
    "tuner = Tuner(trainer)\n",
    "tuner.lr_find(model, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ef6dd07bac4272f716e725ea8b79349a1e1a5da9c3680ee7af3d80a9646d624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
