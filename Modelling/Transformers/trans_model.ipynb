{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Seznam/small-e-czech were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at Seznam/small-e-czech and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, RobertaForSequenceClassification\n",
    "from transformers import ElectraForPreTraining, ElectraTokenizerFast, AutoTokenizer\n",
    "small = AutoModelForSequenceClassification.from_pretrained(\"Seznam/small-e-czech\")\n",
    "robeczech = AutoModelForSequenceClassification.from_pretrained(\"ufal/robeczech-base\")\n",
    "r_tok = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\")\n",
    "s_tok = AutoTokenizer.from_pretrained(\"Seznam/small-e-czech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FineTunedClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 classifier = FineTunedClassifier.load_from_checkpoint(<span style=\"color: #808000; text-decoration-color: #808000\">\"projects/Server-Deep-Learning/86w</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1532</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_from_checkpoint</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1529 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">pretrained_model.freeze()</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1530 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">y_hat = pretrained_model(x)</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1531 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1532 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loaded = _load_from_checkpoint(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1533 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>,                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1534 │   │   │   </span>checkpoint_path,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1535 │   │   │   </span>map_location,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">saving.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">90</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_from_checkpoint</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 87 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">issubclass</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, pl.LightningDataModule):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 88 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _load_state(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, checkpoint, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 89 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">issubclass</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, pl.LightningModule):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 90 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _load_state(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, checkpoint, strict=strict, **kwargs)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 91 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Unsupported {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span><span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">saving.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">136</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_state</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   # filter kwargs according to class init unless it allows any argument via kwargs</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   │   </span>_cls_kwargs = {k: v <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> _cls_kwargs.items() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> cls_init_args_name}    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>136 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>obj = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(**_cls_kwargs)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(obj, pl.LightningModule):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   # give model a chance to load something</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FineTunedClassifier.__init__</span><span style=\"font-weight: bold\">()</span> missing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> required positional arguments: <span style=\"color: #008000; text-decoration-color: #008000\">'scheduler'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'optimizer'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 classifier = FineTunedClassifier.load_from_checkpoint(\u001b[33m\"\u001b[0m\u001b[33mprojects/Server-Deep-Learning/86w\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mcore/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1532\u001b[0m in \u001b[92mload_from_checkpoint\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1529 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mpretrained_model.freeze()\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1530 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33my_hat = pretrained_model(x)\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1531 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1532 \u001b[2m│   │   \u001b[0mloaded = _load_from_checkpoint(                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1533 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mcls\u001b[0m,                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1534 \u001b[0m\u001b[2m│   │   │   \u001b[0mcheckpoint_path,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1535 \u001b[0m\u001b[2m│   │   │   \u001b[0mmap_location,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mcore/\u001b[0m\u001b[1;33msaving.py\u001b[0m:\u001b[94m90\u001b[0m in \u001b[92m_load_from_checkpoint\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96missubclass\u001b[0m(\u001b[96mcls\u001b[0m, pl.LightningDataModule):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 88 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _load_state(\u001b[96mcls\u001b[0m, checkpoint, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 89 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96missubclass\u001b[0m(\u001b[96mcls\u001b[0m, pl.LightningModule):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 90 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _load_state(\u001b[96mcls\u001b[0m, checkpoint, strict=strict, **kwargs)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUnsupported \u001b[0m\u001b[33m{\u001b[0m\u001b[96mcls\u001b[0m\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mcore/\u001b[0m\u001b[1;33msaving.py\u001b[0m:\u001b[94m136\u001b[0m in \u001b[92m_load_state\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   \u001b[0m_cls_kwargs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m _cls_kwargs.items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m cls_init_args_name}    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m136 \u001b[2m│   \u001b[0mobj = \u001b[96mcls\u001b[0m(**_cls_kwargs)                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(obj, pl.LightningModule):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# give model a chance to load something\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mFineTunedClassifier.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m2\u001b[0m required positional arguments: \u001b[32m'scheduler'\u001b[0m and \u001b[32m'optimizer'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = FineTunedClassifier.load_from_checkpoint(\"projects/Server-Deep-Learning/86w86r5z/checkpoints/epoch=6-step=46111.ckpt\", optimizer=None, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = load_from_disk(\"/home/kydliceh/.cache/LM/512/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst[1:4][\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "maximum = 0\n",
    "minimum = 1000\n",
    "for x in dst[\"input_ids\"]:\n",
    "    maximum = max(maximum, x.shape[0])\n",
    "    minimum = min(minimum, x.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(51926)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(dst[140:150][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datamodules import NewsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = NewsDataModule(\"server\", 6, \"ufal/robeczech-base\", \".cache\", 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [45487, 90], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Ahoj, ahoj\", truncation=True, max_length=2, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "max_length = 512\n",
    "trun_type = \"end\"\n",
    "\n",
    "def truncate_tokenized(tokenized):\n",
    "    if trun_type == \"start\":\n",
    "        truncated = tokenized[:max_length]\n",
    "    elif trun_type == \"end\":\n",
    "        truncated = tokenized[-max_length:]\n",
    "    # CLS and SEP tokens\n",
    "    truncated[0] = tokenized[0]\n",
    "    truncated[-1] = tokenized[-1]\n",
    "    return truncated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\", use_fast=True)\n",
    "    content = examples[\"content\"]\n",
    "    tokenized = tokenizer(content, truncation=False, padding=False)\n",
    "    for key in [\"input_ids\", \"attention_mask\"]:\n",
    "        tokenized[key] = [truncate_tokenized(x) for x in tokenized[key]]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = NewsDataModule(\"server\", 6, \"ufal/robeczech-base\", \".cache\", 512, trunc_type=\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97580c16c37642489d77918143b71418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dst = dst.map(mod.tokenize, batched=True, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebce9e153724e91be38ab776fe1f28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dst.filter(lambda batch: [x != 0 for x in batch[\"server\"]], batched=True, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkydlicek-hynek\u001b[0m (\u001b[33mhynky\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/lnet/aic/personal/kydliceh/Articles_Analysis/Modelling/Transformers/wandb/run-20230330_181149-q1mdjidq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hynky/Articles_Analysis-Modelling_Transformers/runs/q1mdjidq' target=\"_blank\">firm-dew-1</a></strong> to <a href='https://wandb.ai/hynky/Articles_Analysis-Modelling_Transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hynky/Articles_Analysis-Modelling_Transformers' target=\"_blank\">https://wandb.ai/hynky/Articles_Analysis-Modelling_Transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hynky/Articles_Analysis-Modelling_Transformers/runs/q1mdjidq' target=\"_blank\">https://wandb.ai/hynky/Articles_Analysis-Modelling_Transformers/runs/q1mdjidq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-180025qn:best, 1442.23MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:59.4\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init()\n",
    "ref = wandb.use_artifact(\"hynky/Lm-Deep-Learning/model-180025qn:best\")\n",
    "ref_dir = ref.download()\n",
    "chcpk_path = ref_dir / \"model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chcpk_path=\"artifacts/model-180025qn:v0/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LMModel\n",
    "\n",
    "classifier = LMModel.load_from_checkpoint(chcpk_path, optimizer=None, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(51961, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=51961, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model.push_to_hub(\"hynky/hyneczech-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512,\n",
       " 512,\n",
       " 512,\n",
       " 166,\n",
       " 99,\n",
       " 123,\n",
       " 107,\n",
       " 512,\n",
       " 337,\n",
       " 512,\n",
       " 328,\n",
       " 458,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 407,\n",
       " 199,\n",
       " 256,\n",
       " 112,\n",
       " 389,\n",
       " 512,\n",
       " 512,\n",
       " 230,\n",
       " 281,\n",
       " 90,\n",
       " 319,\n",
       " 512,\n",
       " 264,\n",
       " 419,\n",
       " 512,\n",
       " 512,\n",
       " 96,\n",
       " 366,\n",
       " 191,\n",
       " 193,\n",
       " 512,\n",
       " 330,\n",
       " 512,\n",
       " 291,\n",
       " 512,\n",
       " 361,\n",
       " 512,\n",
       " 387,\n",
       " 314,\n",
       " 333,\n",
       " 512,\n",
       " 512,\n",
       " 490,\n",
       " 512,\n",
       " 481,\n",
       " 225,\n",
       " 512,\n",
       " 217,\n",
       " 147,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 368,\n",
       " 320,\n",
       " 512,\n",
       " 195,\n",
       " 493,\n",
       " 512,\n",
       " 512,\n",
       " 129,\n",
       " 295,\n",
       " 512,\n",
       " 229,\n",
       " 308,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 473,\n",
       " 96,\n",
       " 283,\n",
       " 512,\n",
       " 471,\n",
       " 306,\n",
       " 311,\n",
       " 140,\n",
       " 261,\n",
       " 166,\n",
       " 218,\n",
       " 512,\n",
       " 512,\n",
       " 510,\n",
       " 130,\n",
       " 319,\n",
       " 190,\n",
       " 232,\n",
       " 512,\n",
       " 432,\n",
       " 222,\n",
       " 338,\n",
       " 482,\n",
       " 147,\n",
       " 232,\n",
       " 366,\n",
       " 220]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in dst[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m maximum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dm\u001b[39m.\u001b[39mtrain_dataloader():\n\u001b[1;32m      3\u001b[0m     maximum \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(maximum, torch\u001b[39m.\u001b[39mmax(x[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m      4\u001b[0m     \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mall(x[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"
     ]
    }
   ],
   "source": [
    "maximum = 0\n",
    "for x in dm.train_dataloader():\n",
    "    maximum = max(maximum, torch.max(x[\"input_ids\"]))\n",
    "    assert torch.all(x[\"attention_mask\"] == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Full Code:\n",
    "import torch\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from timm import create_model\n",
    "\n",
    "\n",
    "class CIFAR10DataModule(L.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, batch_size = 32) -> None:\n",
    "        super().__init__()\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        )\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_set = torchvision.datasets.CIFAR10(\n",
    "            root=\"~/data\", train=True, download=True, transform=self.transform\n",
    "        )\n",
    "        self.test_set = torchvision.datasets.CIFAR10(\n",
    "            root=\"~/data\", train=False, download=True, transform=self.transform\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
    "        )\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.compile(\n",
    "            create_model(\"resnet18\", num_classes=10)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy_score = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def common_step(self, x, y, stage):\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = self.accuracy_score(logits, y)\n",
    "        self.log(\n",
    "            f\"{stage}_loss\", loss, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{stage}_acc\", acc, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, acc = self.common_step(x, y, \"train\")\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, acc = self.common_step(x, y, \"test\")\n",
    "        return {\"test_loss\": loss, \"test_acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def main():\n",
    "    datamodule = CIFAR10DataModule()\n",
    "    model = LitModel()\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=3,\n",
    "        devices=\"auto\",\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    test_result = trainer.test(ckpt_path=\"best\", datamodule=datamodule)\n",
    "    print(test_result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944c013d6394406f99456e64b6f6d8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-0cbab0cb100c6b2f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2569c3283e343ebb31a4dec51005eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09505323789d4444b9513a8e2c3a2062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/279M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51255e97f90e4e988e6134badc4cc35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/288M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786e058453614cca803a004597100e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/284M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7224fe4585af4c0a998ea1513008a142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b6b540af7341e78f2f840b08bc0a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/319M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a326123409bc4b4b8d68229e48767fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/332M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecff39f4c7f641b2864f685cba311a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/324M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811fb785540049888f78eb7cd17623d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445803018017449e9a7036d5e10b8dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/325M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbdcd1337a94daeaabdca20e84f4b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/264M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c821210e4ae4942918623feeca79185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a0d5e65cee4dd8b2108f5c6a35414f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/122056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94f8a4c524240b693b4df83dac814ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1383298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc61757aed7245128333b9e44ce46d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/122056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-0cbab0cb100c6b2f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a2f45932784fbdbec60f5608f2a734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dst = load_dataset(\"hynky/czech_news_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d128a6f73742689c50aee2a70f0fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/122056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ab8de44f214f40ac80b0cf2c98cebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1383298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a844ee5ddf45f4baac3e05e4941466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/122056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys = [\"server\", \"authors_cum_gender\", \"category\", \"day_of_week\"]\n",
    "dst = dst.filter(lambda x: all([y != 0 for y in [x[key] for key in keys]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenghts = [len(x) for x in dst[\"train\"][\"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len = sum(lenghts) / len(lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nchars_to_ntokens_approx(1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def nchars_to_ntokens_approx(nchars):\n",
    "    #returns an estimate of #tokens corresponding to #characters nchars\n",
    "    return max(0,int((nchars)*math.exp(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst[\"train\"].features[\"authors_cum_gender\"].int2str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 50000\n",
    "TEST_SIZE = 10000\n",
    "train_gpt_dst = dst[\"train\"].select(range(len(dst[\"train\"]) - TRAIN_SIZE, len(dst[\"train\"])))\n",
    "test_gpt_dst = dst[\"test\"].shuffle().select(range(TEST_SIZE))\n",
    "test_human_dst = dst[\"test\"].shuffle().select(range(100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-62438212bae7f23d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43952631fa947c095c38b8df7b6bc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dst = load_dataset(\"hynky/czech_news_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_gender ={\n",
    "    \"MAN\": \"Muž\",\n",
    "    \"WOMAN\": \"Žena\",\n",
    "    \"MIXED\": \"Smíšené pohlaví\"\n",
    "}\n",
    "trans_server = {\n",
    "    \"denik\": \"Deník.cz\",\n",
    "    \"idnes\": \"iDNES.cz\",\n",
    "    \"seznamzpravy\": \"SeznamZprávy\",\n",
    "    \"aktualne\": \"Aktuálně.cz\",\n",
    "    \"novinky\": \"Novinky.cz\",\n",
    "    \"irozhlas\": \"iRozhlas.cz\",\n",
    "}\n",
    "trans_day_of_week = {\n",
    "    \"MONDAY\": \"Pondělí\",\n",
    "    \"TUESDAY\": \"Úterý\",\n",
    "    \"WEDNESDAY\": \"Středa\",\n",
    "    \"THURSDAY\": \"Čtvrtek\",\n",
    "    \"FRIDAY\": \"Pátek\",\n",
    "    \"SATURDAY\": \"Sobota\",\n",
    "    \"SUNDAY\": \"Neděle\",\n",
    "}\n",
    "\n",
    "trans_category = {n: n for n in dst[\"train\"].features[\"category\"].names}\n",
    "trans = {\n",
    "    \"authors_cum_gender\": trans_gender,\n",
    "    \"category\": trans_category,\n",
    "    \"day_of_week\": trans_day_of_week,\n",
    "    \"server\": trans_server\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '„Věděli jsme, že Baník přijede bránit a držet remízu. Měli jsme štěstí, že jsme dali docela brzo gól, a pak bylo rozhodující, kdy přidáme druhý, nebo nám Baník uteče z nějaké brejku a srovná. Podařilo se nám dát na 2:0 a uklidnit se,“ vysvětloval Radiožurnálu po zápase Slavie s Baníkem Lukáš Masopust, který zvýšil náskok sešívaných v 70. minutě, krátce po svém příchodu na hřiště. Nakonec mohli fanoušci Slavie slavit s hráči hned čtyřikrát. A to v základní sestavě Slavie byli jen čtyři hráči, kteří byli v základu také ve čtvrtek v Andalusii při remíze 2:2 v úvodním osmifinále Evropské ligy na hřišti Sevilly. „Ve všech řadách to byl velmi dobrý výkon i po změnách. Buď to byli noví hráči, kteří dlouho nehráli a nejsou tak sehraní, nebo měli za sebou náročný program. I když výsledek vypadá jednoznačně, Baník byl týmem z top čtyřky, i když výsledek vypadá jednoznačně,“ cení si výhry Jindřich Trpišovský. Sešívaní totiž krátce po návratu ze Sevilly využili široký kádr a proti Baníku naskočili v sestavě rovnou se sedmi změnami. Přesto tým fungoval. „Zásah byl velký, ale jsme dlouho pohromadě. Kromě tří příchozích hráčů je tým spolu od léta. Kdybychom tohle postoupili v pátém šestém kole, vypadalo by to hůř. Spoustu nácviků máme dohromady, kluci hrají spolu a v různém složení,“ vysvětloval trenér slávistických fotbalistů. Ofenzivní sestava V sestavě tak byl i kapitán a střelec prvního g',\n",
       " 'completion': 'iRozhlas.cz Sport Muž Pondělí'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 1400\n",
    "features = dst[\"train\"].features\n",
    "def convert_for_gpt3(examples):\n",
    "    truncated_content = examples[\"content\"][:max_length]\n",
    "    keys = [ \"server\",  \"category\", \"authors_cum_gender\", \"day_of_week\"]\n",
    "    retrieved_keys = {key: trans[key][features[key].int2str(examples[key])] for key in keys}\n",
    "    return {\n",
    "        \"prompt\": truncated_content,\n",
    "        \"completion\": \" \".join([value for value in retrieved_keys.values()]),\n",
    "    }\n",
    "convert_for_gpt3(dst[\"train_small\"][0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-62438212bae7f23d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-89aeb3c4017bc603.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff53c26780d4b99b070ff9cad0d0afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dst = dst[\"train_small\"].map(convert_for_gpt3)\n",
    "test_dst = dst[\"test_small\"].map(convert_for_gpt3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "new_dst = DatasetDict({\n",
    "    \"train\": full_dst[\"train\"],\n",
    "    \"validation\": full_dst[\"test\"],\n",
    "    \"test\": full_dst[\"test\"],\n",
    "    \"train_small\": train_gpt_dst,\n",
    "    \"test_small\": test_gpt_dst,\n",
    "    \"test_human\": test_human_dst\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd28809e7f8940da9c2d34f039646735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc48437b2d1459184f209587a502685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bb552678414f9d96dc59bbf77f1de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd2d7d71cd94e1f9aa3a667f258f13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42d0fa0c3c2410187ebc32bb9fabe5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fed35aab0943c7902e6d778b69f346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e965cf590449bf9a90eccc4f27a1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15ed8f09c2644d09bbe8a4011a5b5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760df346d910422d8fc0cf832f8621d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/173 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5580d9b0dd8a4a93a6956e8900318123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647661295d3a4250880e3175271421f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2790ccf672224351b56c5a6bc0f804e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/123 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a906826a094c4a816b601cdd88084b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f8f3adc4d946c7a20092a844c9db9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012dfc176fa24c45b84ae1ce248832d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/123 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab04e4d1d3474c7dbef025d23c2c9914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train_small to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4028feb300e14edb9dc026b0d71ab41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764cdd3540ea40cf8844c8532f71c230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test_small to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661c85b02bd84428ac54aead0c1f76ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec7f92a3ad443fbaed6c76b963f284c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test_human to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de9207889b143bc9e88cb417030f0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78217b98ce443dbb1f0012b166577e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_dst.push_to_hub(\"hynky/czech_news_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dst = train_dst.remove_columns(set(train_dst.column_names) - {\"query\", \"completion\"})\n",
    "test_dst = test_dst.remove_columns(set(test_dst.column_names) - {\"query\", \"completion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dst.to_pandas()\n",
    "test_df = test_dst.to_pandas()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a770d580949144c6a8012c3ef086f856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "395751"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = test_human_dst.remove_columns(set(test_human_dst.column_names) - {\"content\", \"url\"} - set(keys))\n",
    "tmp.to_csv(\"test_human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(\"gpt3-train.jsonl\", orient='records', lines=True)\n",
    "test_df.to_json(\"gpt3-test.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dataset(\"hynky/czech_news_dataset\", split=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ef6dd07bac4272f716e725ea8b79349a1e1a5da9c3680ee7af3d80a9646d624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
