{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Seznam/small-e-czech were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at Seznam/small-e-czech and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, RobertaForSequenceClassification\n",
    "from transformers import ElectraForPreTraining, ElectraTokenizerFast, AutoTokenizer\n",
    "small = AutoModelForSequenceClassification.from_pretrained(\"Seznam/small-e-czech\")\n",
    "robeczech = AutoModelForSequenceClassification.from_pretrained(\"ufal/robeczech-base\")\n",
    "r_tok = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\")\n",
    "s_tok = AutoTokenizer.from_pretrained(\"Seznam/small-e-czech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FineTunedClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 classifier = FineTunedClassifier.load_from_checkpoint(<span style=\"color: #808000; text-decoration-color: #808000\">\"projects/Server-Deep-Learning/86w</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1532</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_from_checkpoint</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1529 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">pretrained_model.freeze()</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1530 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">y_hat = pretrained_model(x)</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1531 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1532 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loaded = _load_from_checkpoint(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1533 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>,                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1534 │   │   │   </span>checkpoint_path,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1535 │   │   │   </span>map_location,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">saving.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">90</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_from_checkpoint</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 87 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">issubclass</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, pl.LightningDataModule):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 88 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _load_state(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, checkpoint, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 89 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">issubclass</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, pl.LightningModule):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 90 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _load_state(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, checkpoint, strict=strict, **kwargs)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 91 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Unsupported {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span><span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">saving.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">136</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_state</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   # filter kwargs according to class init unless it allows any argument via kwargs</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   │   </span>_cls_kwargs = {k: v <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> _cls_kwargs.items() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> cls_init_args_name}    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>136 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>obj = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(**_cls_kwargs)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(obj, pl.LightningModule):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   # give model a chance to load something</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FineTunedClassifier.__init__</span><span style=\"font-weight: bold\">()</span> missing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> required positional arguments: <span style=\"color: #008000; text-decoration-color: #008000\">'scheduler'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'optimizer'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 classifier = FineTunedClassifier.load_from_checkpoint(\u001b[33m\"\u001b[0m\u001b[33mprojects/Server-Deep-Learning/86w\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mcore/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1532\u001b[0m in \u001b[92mload_from_checkpoint\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1529 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mpretrained_model.freeze()\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1530 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33my_hat = pretrained_model(x)\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1531 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1532 \u001b[2m│   │   \u001b[0mloaded = _load_from_checkpoint(                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1533 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mcls\u001b[0m,                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1534 \u001b[0m\u001b[2m│   │   │   \u001b[0mcheckpoint_path,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1535 \u001b[0m\u001b[2m│   │   │   \u001b[0mmap_location,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mcore/\u001b[0m\u001b[1;33msaving.py\u001b[0m:\u001b[94m90\u001b[0m in \u001b[92m_load_from_checkpoint\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96missubclass\u001b[0m(\u001b[96mcls\u001b[0m, pl.LightningDataModule):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 88 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _load_state(\u001b[96mcls\u001b[0m, checkpoint, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 89 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96missubclass\u001b[0m(\u001b[96mcls\u001b[0m, pl.LightningModule):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 90 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _load_state(\u001b[96mcls\u001b[0m, checkpoint, strict=strict, **kwargs)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUnsupported \u001b[0m\u001b[33m{\u001b[0m\u001b[96mcls\u001b[0m\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mcore/\u001b[0m\u001b[1;33msaving.py\u001b[0m:\u001b[94m136\u001b[0m in \u001b[92m_load_state\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   \u001b[0m_cls_kwargs = {k: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m _cls_kwargs.items() \u001b[94mif\u001b[0m k \u001b[95min\u001b[0m cls_init_args_name}    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m136 \u001b[2m│   \u001b[0mobj = \u001b[96mcls\u001b[0m(**_cls_kwargs)                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(obj, pl.LightningModule):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# give model a chance to load something\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mFineTunedClassifier.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m2\u001b[0m required positional arguments: \u001b[32m'scheduler'\u001b[0m and \u001b[32m'optimizer'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = FineTunedClassifier.load_from_checkpoint(\"projects/Server-Deep-Learning/86w86r5z/checkpoints/epoch=6-step=46111.ckpt\", optimizer=None, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = load_from_disk(\"/home/kydliceh/.cache/LM/512/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst[1:4][\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "maximum = 0\n",
    "minimum = 1000\n",
    "for x in dst[\"input_ids\"]:\n",
    "    maximum = max(maximum, x.shape[0])\n",
    "    minimum = min(minimum, x.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(51926)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(dst[140:150][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datamodules import NewsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = NewsDataModule(\"server\", 6, \"ufal/robeczech-base\", \".cache\", 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [45487, 90], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Ahoj, ahoj\", truncation=True, max_length=2, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "max_length = 512\n",
    "trun_type = \"end\"\n",
    "\n",
    "def truncate_tokenized(tokenized):\n",
    "    if trun_type == \"start\":\n",
    "        truncated = tokenized[:max_length]\n",
    "    elif trun_type == \"end\":\n",
    "        truncated = tokenized[-max_length:]\n",
    "    # CLS and SEP tokens\n",
    "    truncated[0] = tokenized[0]\n",
    "    truncated[-1] = tokenized[-1]\n",
    "    return truncated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ufal/robeczech-base\", use_fast=True)\n",
    "    content = examples[\"content\"]\n",
    "    tokenized = tokenizer(content, truncation=False, padding=False)\n",
    "    for key in [\"input_ids\", \"attention_mask\"]:\n",
    "        tokenized[key] = [truncate_tokenized(x) for x in tokenized[key]]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = NewsDataModule(\"server\", 6, \"ufal/robeczech-base\", \".cache\", 512, trunc_type=\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97580c16c37642489d77918143b71418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dst = dst.map(mod.tokenize, batched=True, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebce9e153724e91be38ab776fe1f28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dst.filter(lambda batch: [x != 0 for x in batch[\"server\"]], batched=True, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512,\n",
       " 512,\n",
       " 512,\n",
       " 166,\n",
       " 99,\n",
       " 123,\n",
       " 107,\n",
       " 512,\n",
       " 337,\n",
       " 512,\n",
       " 328,\n",
       " 458,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 407,\n",
       " 199,\n",
       " 256,\n",
       " 112,\n",
       " 389,\n",
       " 512,\n",
       " 512,\n",
       " 230,\n",
       " 281,\n",
       " 90,\n",
       " 319,\n",
       " 512,\n",
       " 264,\n",
       " 419,\n",
       " 512,\n",
       " 512,\n",
       " 96,\n",
       " 366,\n",
       " 191,\n",
       " 193,\n",
       " 512,\n",
       " 330,\n",
       " 512,\n",
       " 291,\n",
       " 512,\n",
       " 361,\n",
       " 512,\n",
       " 387,\n",
       " 314,\n",
       " 333,\n",
       " 512,\n",
       " 512,\n",
       " 490,\n",
       " 512,\n",
       " 481,\n",
       " 225,\n",
       " 512,\n",
       " 217,\n",
       " 147,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 368,\n",
       " 320,\n",
       " 512,\n",
       " 195,\n",
       " 493,\n",
       " 512,\n",
       " 512,\n",
       " 129,\n",
       " 295,\n",
       " 512,\n",
       " 229,\n",
       " 308,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 473,\n",
       " 96,\n",
       " 283,\n",
       " 512,\n",
       " 471,\n",
       " 306,\n",
       " 311,\n",
       " 140,\n",
       " 261,\n",
       " 166,\n",
       " 218,\n",
       " 512,\n",
       " 512,\n",
       " 510,\n",
       " 130,\n",
       " 319,\n",
       " 190,\n",
       " 232,\n",
       " 512,\n",
       " 432,\n",
       " 222,\n",
       " 338,\n",
       " 482,\n",
       " 147,\n",
       " 232,\n",
       " 366,\n",
       " 220]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in dst[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m maximum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dm\u001b[39m.\u001b[39mtrain_dataloader():\n\u001b[1;32m      3\u001b[0m     maximum \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(maximum, torch\u001b[39m.\u001b[39mmax(x[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m      4\u001b[0m     \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mall(x[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"
     ]
    }
   ],
   "source": [
    "maximum = 0\n",
    "for x in dm.train_dataloader():\n",
    "    maximum = max(maximum, torch.max(x[\"input_ids\"]))\n",
    "    assert torch.all(x[\"attention_mask\"] == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Full Code:\n",
    "import torch\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from timm import create_model\n",
    "\n",
    "\n",
    "class CIFAR10DataModule(L.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, batch_size = 32) -> None:\n",
    "        super().__init__()\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        )\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_set = torchvision.datasets.CIFAR10(\n",
    "            root=\"~/data\", train=True, download=True, transform=self.transform\n",
    "        )\n",
    "        self.test_set = torchvision.datasets.CIFAR10(\n",
    "            root=\"~/data\", train=False, download=True, transform=self.transform\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
    "        )\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.compile(\n",
    "            create_model(\"resnet18\", num_classes=10)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy_score = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def common_step(self, x, y, stage):\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = self.accuracy_score(logits, y)\n",
    "        self.log(\n",
    "            f\"{stage}_loss\", loss, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{stage}_acc\", acc, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, acc = self.common_step(x, y, \"train\")\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss, acc = self.common_step(x, y, \"test\")\n",
    "        return {\"test_loss\": loss, \"test_acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def main():\n",
    "    datamodule = CIFAR10DataModule()\n",
    "    model = LitModel()\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=3,\n",
    "        devices=\"auto\",\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    test_result = trainer.test(ckpt_path=\"best\", datamodule=datamodule)\n",
    "    print(test_result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031531044f15461ab045b14431283995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-0cbab0cb100c6b2f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d427c65427fd4566af63aff12a4df69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe288050b064d3e9ac6674dc4a473d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/279M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193df09860f144ab83f8f0552b8936a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/264M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6e0c25a79b43d4b2530193ad30d87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/288M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3440311b2a3f442dae1dcc86f5857ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/284M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd2f3c2123a44b49e2399f61c91520f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382a0c5f5a6c4ab685597eb893bd4fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/319M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8cea2a4b884aaebeb6bb3fcafd521f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/332M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9e1e8972664223ab82e13d2271c50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/324M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa390667d304c189fc224397e93303b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6562cb85efd04667b94aa55a26dce5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/325M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af71eabc74a94b6fbe580f4056c8b56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc83bd718894bbc8a1c6cca62d5a336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/122056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84512877a59b41b6aeae766f80217b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/122056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961cf745070940ae900ef9e0974ce0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1383298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-0cbab0cb100c6b2f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80af0549f15b49889d54c0a08f66af20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dst = load_dataset(\"hynky/czech_news_dataset\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-0cbab0cb100c6b2f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-03b5f3701586bbc9.arrow\n",
      "Loading cached processed dataset at /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-0cbab0cb100c6b2f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b92e720c79b8f82e.arrow\n",
      "Loading cached processed dataset at /home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-0cbab0cb100c6b2f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-2171c3bccd434849.arrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keys = [\"server\", \"authors_cum_gender\", \"category\", \"day_of_week\"]\n",
    "dst = dst.filter(lambda x: all([y != 0 for y in [x[key] for key in keys]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenghts = [len(x) for x in dst[\"train\"][\"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len = sum(lenghts) / len(lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nchars_to_ntokens_approx(1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def nchars_to_ntokens_approx(nchars):\n",
    "    #returns an estimate of #tokens corresponding to #characters nchars\n",
    "    return max(0,int((nchars)*math.exp(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst[\"train\"].features[\"authors_cum_gender\"].int2str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_gender ={\n",
    "    \"MAN\": \"Muž\",\n",
    "    \"WOMAN\": \"Žena\",\n",
    "    \"MIXED\": \"Smíšené pohlaví\"\n",
    "}\n",
    "trans_server = {\n",
    "    \"denik\": \"Deník.cz\",\n",
    "    \"idnes\": \"iDNES.cz\",\n",
    "    \"seznamzpravy\": \"SeznamZprávy\",\n",
    "    \"aktualne\": \"Aktuálně.cz\",\n",
    "    \"novinky\": \"Novinky.cz\",\n",
    "    \"irozhlas\": \"iRozhlas.cz\",\n",
    "}\n",
    "trans_day_of_week = {\n",
    "    \"MONDAY\": \"Pondělí\",\n",
    "    \"TUESDAY\": \"Úterý\",\n",
    "    \"WEDNESDAY\": \"Středa\",\n",
    "    \"THURSDAY\": \"Čtvrtek\",\n",
    "    \"FRIDAY\": \"Pátek\",\n",
    "    \"SATURDAY\": \"Sobota\",\n",
    "    \"SUNDAY\": \"Neděle\",\n",
    "}\n",
    "\n",
    "trans_category = {n: n for n in dst[\"train\"].features[\"category\"].names}\n",
    "trans = {\n",
    "    \"authors_cum_gender\": trans_gender,\n",
    "    \"category\": trans_category,\n",
    "    \"day_of_week\": trans_day_of_week,\n",
    "    \"server\": trans_server\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Telefon má spoustu zajímavých funkcí. Jednou z nich je například i funkce hlasového vytáčení a ovládání telefonu. Mobil má paměť na 15 hlasových povelů, které jsou volně sdílené mezi povely pro vytočení určitého čísla a dále mohou být přiřazeny až k 25 dalším funkcím (příkazům) telefonu. V souvislosti s hlasovými funkcemi je zde i paměť na 20 sekundovou hlasovou nahrávku, což není mnoho, ale pro občasnou potřebu to bohatě stačí. Hmotnostně patří Xenium spíše ke kolibříkům. Považte sami, 95 gramů ještě dnes nemá kdejaký telefon. Rozměry 109x41x20 mm jsou přijatelné celkem i pro kapsičku u košile. Další funkcí, kterou disponuje Xenium je vibrační zvonění, což není dnes již neobvyklé. Snad jen, kdyby se tento telefon zaměřil na střední cenovou třídu. Skládání vlastních melodií se dnes již vyžaduje také snad od každého mobilu. Tento přístroj editorem na melodie rovněž disponuje. Dále je zde tzv. Brick game, což my spektristé známe pod jménem Arkanoid. Je až s podivem, jak rychle se tito plýtvači energie a snižovači životnosti zabydleli v nových typech mobilních telefonů. Takové hry ovšem vyžadují poměrně kvalitní displej, který je zde plně grafický o rozlišení 87x64 bodů. Displej je modře podsvícen. Velmi dobře je řešeno rovněž ovládání telefonu, které se odehrává podobně jako u telefonů Sony pomocí hlavního tlačítka, které se jmenuje Pilot Key. Výdrž mobilu závisí na použité bater',\n",
       " 'completion': 'iDNES.cz Technologie Muž Čtvrtek'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 1400\n",
    "features = dst[\"train\"].features\n",
    "def convert_for_gpt3(examples):\n",
    "    truncated_content = examples[\"content\"][:max_length]\n",
    "    keys = [ \"server\",  \"category\", \"authors_cum_gender\", \"day_of_week\"]\n",
    "    retrieved_keys = {key: trans[key][features[key].int2str(examples[key])] for key in keys}\n",
    "    return {\n",
    "        \"query\": truncated_content,\n",
    "        \"completion\": \" \".join([value for value in retrieved_keys.values()]),\n",
    "    }\n",
    "convert_for_gpt3(dst[\"train\"][0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(473013, 523013)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 50000\n",
    "TEST_SIZE = 10000\n",
    "train_dst = dst[\"train\"].select(range(len(dst[\"train\"]) - TRAIN_SIZE, len(dst[\"train\"])))\n",
    "test_dst = dst[\"test\"].shuffle().select(range(TEST_SIZE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2304694312cc44fa93100f902dd9fbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25102653f7b8481bb3c331ac60c64ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dst = train_dst.map(convert_for_gpt3)\n",
    "test_dst = test_dst.map(convert_for_gpt3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dst = train_dst.remove_columns(set(train_dst.column_names) - {\"query\", \"completion\"})\n",
    "test_dst = test_dst.remove_columns(set(test_dst.column_names) - {\"query\", \"completion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dst.to_pandas()\n",
    "test_df = test_dst.to_pandas()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(\"gpt3-train.jsonl\", orient='records', lines=True)\n",
    "test_df.to_json(\"gpt3-test.jsonl\", orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ef6dd07bac4272f716e725ea8b79349a1e1a5da9c3680ee7af3d80a9646d624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
