{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kydliceh/Projects/Bakalarka-code/myvenv/lib64/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ufal/robeczech-base\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(51961, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_head.decoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from datamodules import NewsDataModuleForLM\n",
    "dm = NewsDataModuleForLM(cache_dir=\"cache\", batch_size=2, limit=1000, tokenizer=\"ufal/robeczech-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.batch_size = 2\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.mlm = 0.15\n",
    "\n",
    "ld = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "z = next(iter(ld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "        [2590, -100, -100,  ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from optims import get_no_bias_weight_adamw\n",
    "from schedulers import get_linear_schedule_warmup\n",
    "part_optim = partial(get_no_bias_weight_adamw, lr=1e-5, weight_decay=0.01, betas=(0.9, 0.999), eps=1e-6)\n",
    "part_sched = partial(get_linear_schedule_warmup, num_warmup_steps=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LLMModel\n",
    "model = LLMModel(\"ufal/robeczech-base\", part_optim, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "trainer = pl.Trainer(accelerator=\"cpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type               | Params\n",
      "-----------------------------------------------\n",
      "0 | model   | RobertaForMaskedLM | 126 M \n",
      "1 | metrics | ModuleDict         | 0     \n",
      "-----------------------------------------------\n",
      "126 M     Trainable params\n",
      "0         Non-trainable params\n",
      "126 M     Total params\n",
      "504.007   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1076 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/1076 [00:08<2:31:27,  8.45s/it, loss=nan, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kydliceh/Projects/Bakalarka-code/myvenv/lib64/python3.10/site-packages/lightning/pytorch/loops/optimization/optimizer_loop.py:138: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 6/1076 [00:59<2:55:32,  9.84s/it, loss=nan, v_num=3]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import Callback\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall, ConfusionMatrix, Metric\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MetricStruct:\n",
    "    readable_name: str\n",
    "    metric: Metric\n",
    "    step: bool\n",
    "    epoch: bool\n",
    "\n",
    "\n",
    "class TrainMetricCallback(Callback):\n",
    "    def __init__(self, metric: MetricStruct):\n",
    "        super().__init__()\n",
    "        self.metric = metric\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module) -> None:\n",
    "        if self.metric.epoch:\n",
    "            epoch_value = self.metric.metric.compute()\n",
    "            trainer.logger.log_metrics({f\"train/{self.metric.readable_name}\": epoch_value}, step=trainer.global_step)\n",
    "        self.metric.metric.reset()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx) -> None:\n",
    "        labels = batch['labels']\n",
    "        if not isinstance(outputs, dict) or 'logits' not in outputs:\n",
    "            raise ValueError('The `outputs` should be a dict with key `logits`.')\n",
    "        preds = outputs['logits'].argmax(dim=1)\n",
    "        if self.metric.step:\n",
    "            step_value = self.metric.metric(preds, labels)\n",
    "            trainer.logger.log_metrics({f\"train/{self.metric.readable_name}\": step_value}, step=trainer.global_step)\n",
    "        if self.metric.epoch:\n",
    "            self.metric.metric.update(preds, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import BaseFinetuning\n",
    "\n",
    "class SimpleLayersFreezer(BaseFinetuning):\n",
    "    def __init__(self, last_unfreeze_layers: int):\n",
    "        super().__init__()\n",
    "        self.last_unfreeze_layers = last_unfreeze_layers\n",
    "\n",
    "    def finetune_function(\n",
    "        self, pl_module: \"pl.LightningModule\", epoch: int, optimizer, opt_idx: int\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def freeze_before_training(self, model):\n",
    "        self.freeze(model)\n",
    "        # Classifier unfreeze\n",
    "        if hasattr(model.pretrained_model, \"classifier\"):\n",
    "            self.make_trainable(model.pretrained_model.classifier)\n",
    "        # Last freeze_layers layers unfreeze\n",
    "        if hasattr(model.pretrained_model, 'roberta') and hasattr(model.pretrained_model.roberta, 'encoder'):\n",
    "            self.make_trainable(model.pretrained_model.roberta.encoder.layer[-self.last_unfreeze_layers:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from lightning import LightningModule \n",
    "import torch\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from transformers import AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall, ConfusionMatrix, Metric\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MetricStruct:\n",
    "    readable_name: str\n",
    "    metric: Metric\n",
    "    step: bool\n",
    "    epoch: bool\n",
    "    \n",
    "\n",
    "def prepare_confussion_matrix_for_logging(confusion_matrix, class_names):\n",
    "    data = []\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            data.append((\n",
    "                class_names[i],\n",
    "                class_names[j],\n",
    "                confusion_matrix[i, j]\n",
    "            ))\n",
    "    return data, [\"Actual\", \"Predicted\", \"Count\"]\n",
    "\n",
    "class FineTunedRobeCzech(LightningModule):\n",
    "    def __init__(self, model_chp, class_names, train_metrics: List[MetricStruct], val_metrics: List[MetricStruct], test_metrics: List[MetricStruct], lr=2e-5, warmup_steps=1000, betas=(0.9, 0.98), eps=1e-08, weight_decay=0.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.pretrained_model = self.get_model(model_chp, len(class_names))\n",
    "        self.metrics = {\n",
    "            \"train\": train_metrics,\n",
    "            \"val\": val_metrics,\n",
    "            \"test\": test_metrics\n",
    "        }\n",
    "\n",
    "    def get_model(self, model_chp, num_dim):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_chp, num_labels=num_dim)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def log_metrics(self, output: SequenceClassifierOutput, labels, split):\n",
    "        predicted_labels = torch.argmax(output.logits, dim=1)\n",
    "        self.log(f\"{split}/loss\", output.loss, logger=True, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        for metric_struct in self.metrics[split]:\n",
    "            if metric_struct.step:\n",
    "                step_value = metric_struct.metric(predicted_labels, labels)\n",
    "                self.log(f\"{split}/{metric_struct.readable_name}_step\", step_value, logger=True)\n",
    "            else:\n",
    "                metric_struct.metric.update(predicted_labels, labels)\n",
    "\n",
    "    def log_confussion_matrix(self, cfs_matrix, split):\n",
    "        if not isinstance(self.logger, WandbLogger):\n",
    "            raise Exception(\"Confusion matrix logging is only supported for wandb logger\")\n",
    "        data, cols = prepare_confussion_matrix_for_logging(cfs_matrix, self.hparams.class_names)\n",
    "        self.logger.log_table(f\"{split}/confusion_matrix_{self.current_epoch}\", data=data, columns=cols)\n",
    "\n",
    "\n",
    "    def reset_and_log_metrics(self, split):\n",
    "        for metric_struct in self.metrics[split]:\n",
    "            if metric_struct.epoch:\n",
    "                if isinstance(metric_struct.metric, MulticlassConfusionMatrix):\n",
    "                    cm = metric_struct.metric.compute()\n",
    "                    self.log_confussion_matrix(cm, split)\n",
    "                else:\n",
    "                    self.log(f\"{split}/{metric_struct.readable_name}_epoch\", metric_struct.metric.compute(), logger=True)\n",
    "            metric_struct.metric.reset()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self.pretrained_model(**batch)\n",
    "        self.log_metrics(output, batch[\"labels\"], \"train\")\n",
    "        return output.loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.reset_and_log_metrics(\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self.pretrained_model(**batch)\n",
    "        labels = batch[\"labels\"]\n",
    "        self.log_metrics(output, labels, \"val\")\n",
    "        return output.loss\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.reset_and_log_metrics(\"val\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        output = self.pretrained_model(**batch)\n",
    "        labels = batch[\"labels\"]\n",
    "        self.log_metrics(output, labels ,\"test\")\n",
    "        return output.loss\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        self.reset_and_log_metrics(\"test\")\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        scheduler = None\n",
    "        # Use hugging face settings\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.pretrained_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.pretrained_model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.hparams.lr, eps=self.hparams.eps, betas=self.hparams.betas )\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.warmup_steps,\n",
    "            num_training_steps=self.trainer.estimated_stepping_batches,\n",
    "        )\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train split\n",
      "Preparing validation split\n",
      "Preparing test split\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerBase, AutoTokenizer, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from pathlib import Path\n",
    "from lightning.pytorch import LightningDataModule\n",
    "import shutil\n",
    "\n",
    "class NewsDataModule(LightningDataModule):\n",
    "    def __init__(self, column, tokenizer, max_length=512, batch_size=12, num_proc=4, trunc_type=\"start\", cache_dir=Path(\"cache/czech_news_proc\"), reload_cache=False):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_proc = num_proc\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer, use_fast=True)\n",
    "        self.max_length = max_length\n",
    "        self.column = column\n",
    "        self.trunc_type = trunc_type\n",
    "        self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer, padding=True)\n",
    "        self.cache_dir = cache_dir\n",
    "        self.reload_cache = reload_cache\n",
    "\n",
    "        \n",
    "\n",
    "    def prepare_split(self, split, reload_cache):\n",
    "        print(f\"Preparing {split} split\")\n",
    "        split_cache_dir = self.cache_dir / str(self.max_length) / split\n",
    "        if split_cache_dir.exists():\n",
    "            if not reload_cache:\n",
    "                return\n",
    "            else:\n",
    "                shutil.rmtree(split_cache_dir)\n",
    "                split_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        dataset = load_dataset(str(\"hynky/czech_news_dataset\"), split=split)\n",
    "        dataset = dataset.rename_column(self.column, \"labels\")\n",
    "        cols = {\"labels\", \"attention_mask\", \"input_ids\"}\n",
    "        dataset = dataset.map(lambda batch: self.tokenizer(batch[\"content\"], truncation=True, max_length=self.max_length), keep_in_memory=True, batched=True)\n",
    "        # Remove \"Nones\"\n",
    "        dataset = dataset.map(\n",
    "            lambda batch: {\"labels\": [x - 1 for x in batch[\"labels\"] if x != 0]}, batched=True, num_proc=self.num_proc,\n",
    "            keep_in_memory=True,\n",
    "        )\n",
    "        dataset = dataset.remove_columns(set(dataset.column_names) - cols)\n",
    "        dataset.set_format(\"pt\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "        print(\"Saving\")\n",
    "        dataset.save_to_disk(str(split_cache_dir), num_proc=self.num_proc)\n",
    "\n",
    "    def load_split(self, split):\n",
    "        return load_from_disk(self.cache_dir / str(self.max_length) / split)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.prepare_split(\"train\", reload_cache=self.reload_cache)\n",
    "        self.prepare_split(\"validation\", reload_cache=self.reload_cache)\n",
    "        self.prepare_split(\"test\", reload_cache=self.reload_cache)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = self.load_split(\"train\")\n",
    "            self.val_dataset = self.load_split(\"validation\")\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = self.load_split(\"test\")\n",
    "            \n",
    "\n",
    "    def create_dataloader(self, dataset):\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, num_workers=self.num_proc, collate_fn=self.data_collator, shuffle=True)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.train_dataset)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.val_dataset)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.test_dataset)\n",
    "\n",
    "data_module = NewsDataModule(\"server\", \"ufal/robeczech-base\", reload_cache=False)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ufal/robeczech-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import DeviceStatsMonitor, LearningRateMonitor, ModelCheckpoint, Timer, EarlyStopping\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "column = \"server\"\n",
    "logger = WandbLogger(project=f\"{column}_NN\",log_model=True)\n",
    "class_names = data_module.train_dataset.features[\"labels\"].names[1:]\n",
    "\n",
    "train_metrics, test_metrics, val_metrics =[[\n",
    "    MetricStruct(\"accuracy\", Accuracy(task=\"multiclass\", num_classes=len(class_names)), step=False, epoch=True),\n",
    "    MetricStruct(\"f1_macro\", F1Score(task=\"multiclass\", num_classes=len(class_names), average=\"macro\"), step=True, epoch=True),\n",
    "    MetricStruct(\"f1_micro\",  F1Score(task=\"multiclass\", num_classes=len(class_names), average=\"micro\"), step=True, epoch=True),\n",
    "    MetricStruct(\"precission\", Precision(task=\"multiclass\", num_classes=len(class_names), average=\"macro\"), step=False, epoch=True),\n",
    "    MetricStruct(\"recall\", Recall(task=\"multiclass\", num_classes=len(class_names), average=\"macro\"), step=False, epoch=True),\n",
    "    MetricStruct(\"confusion_matrix\", ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names)), step=False, epoch=True),\n",
    "] for _ in range(3)]\n",
    "\n",
    "model = FineTunedRobeCzech(\"ufal/robeczech-base\", class_names, train_metrics=train_metrics, test_metrics=test_metrics, val_metrics=val_metrics)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "    max_epochs=4,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        SimpleLayersFreezer(2),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        EarlyStopping(monitor=\"val/loss\", patience=3, mode=\"min\"),\n",
    "        ModelCheckpoint(monitor=\"val/loss\", save_top_k=5, mode=\"min\"),\n",
    "        Timer(),\n",
    "    ],\n",
    "    enable_model_summary=True,\n",
    "    enable_progress_bar=True,\n",
    "    logger=logger,\n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    "    limit_test_batches=1,\n",
    "    log_every_n_steps=1,\n",
    "    val_check_interval=1,\n",
    ")\n",
    "\n",
    "#trainer.fit(model, datamodule=data_module)\n",
    "# trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train split\n",
      "Preparing validation split\n",
      "Preparing test split\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">lightning.pytorch.tuner.tuning</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> Tuner                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>tuner = Tuner(trainer)                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>4 tuner.lr_find(model, datamodule=data_module)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">tuner/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tuning.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">267</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">lr_find</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   │   </span>lr_finder_callback._early_exit = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks = [lr_finder_callback] + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>267 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">268 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">269 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks = [cb <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> cb <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.callbacks <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> cb <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> lr_fi   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">270 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">608</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 605 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 606 │   │   </span>model = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_unwrap_optimized(model)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 607 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 608 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 609 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 610 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 611 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">38</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>38 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">40 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> _TunerExitException:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41 │   │   </span>trainer._call_teardown_hook()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">650</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_fit_impl</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 647 │   │   │   </span>model_provided=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 648 │   │   │   </span>model_connected=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lightning_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 649 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 650 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run(model, ckpt_path=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ckpt_path)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 651 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 652 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.stopped                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 653 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1048</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1045 │   │   # SET UP TRAINING</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1047 │   │   </span>log.detail(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}: setting up strategy environment\"</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1048 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy.setup_environment()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1049 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.__setup_profiler()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1050 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1051 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_setup_hook()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># allow user to setup lightning_module in accelerator e</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">strategies/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">strategy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup_environment</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">environment before setup is complete.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.setup_device(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.root_device)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup_optimizers</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trainer: <span style=\"color: #808000; text-decoration-color: #808000\">\"pl.Trainer\"</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Creates optimizers and schedulers.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">accelerators/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">cuda.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">43</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup_device</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> device.type != <span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> MisconfigurationException(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Device should be GPU, got {</span>device<span style=\"color: #808000; text-decoration-color: #808000\">} instead</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 43 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_check_cuda_matmul_precision(device)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 │   │   </span>torch.cuda.set_device(device)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trainer: <span style=\"color: #808000; text-decoration-color: #808000\">\"pl.Trainer\"</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/fabric/a</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ccelerators/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">cuda.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">246</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_cuda_matmul_precision</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _TORCH_GREATER_EQUAL_1_12:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244 │   │   # before 1.12, tf32 was used by default</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">245 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>246 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>major, _ = torch.cuda.get_device_capability(device)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">247 │   </span>ampere_or_later = major &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Ampere and later leverage tensor cores, where this s</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> ampere_or_later:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">357</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_device_capability</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">354 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">355 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tuple(int, int): the major and minor cuda capability of the device</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>357 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>prop = get_device_properties(device)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">358 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> prop.major, prop.minor                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">359 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">371</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_device_properties</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">369 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">_CudaDeviceProperties: the properties of the device</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">370 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>371 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_lazy_init()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># will define _get_device_properties</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">372 │   </span>device = _get_device_index(device, optional=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">373 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> device &lt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> device &gt;= device_count():                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">374 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AssertionError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Invalid device id\"</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">229</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_lazy_init</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 │   │   # are found or any other error occurs</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'CUDA_MODULE_LOADING'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> os.environ:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 │   │   │   </span>os.environ[<span style=\"color: #808000; text-decoration-color: #808000\">'CUDA_MODULE_LOADING'</span>] = <span style=\"color: #808000; text-decoration-color: #808000\">'LAZY'</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>229 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch._C._cuda_init()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 │   │   # Some of the queued calls may reentrantly call _lazy_init();</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 │   │   # we need to just return without initializing in that case.</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">232 │   │   # However, we must not let any *other* threads in!</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA driver initialization failed, you might not have a CUDA gpu.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mlightning\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mpytorch\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtuner\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtuning\u001b[0m \u001b[94mimport\u001b[0m Tuner                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mtuner = Tuner(trainer)                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4 tuner.lr_find(model, datamodule=data_module)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtuner/\u001b[0m\u001b[1;33mtuning.py\u001b[0m:\u001b[94m267\u001b[0m in \u001b[92mlr_find\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   \u001b[0mlr_finder_callback._early_exit = \u001b[94mTrue\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.callbacks = [lr_finder_callback] + \u001b[96mself\u001b[0m.trainer.callbacks             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m267 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m268 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m269 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.callbacks = [cb \u001b[94mfor\u001b[0m cb \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.trainer.callbacks \u001b[94mif\u001b[0m cb \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m lr_fi   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m270 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m608\u001b[0m in \u001b[92mfit\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 605 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 606 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = \u001b[96mself\u001b[0m._maybe_unwrap_optimized(model)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 607 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 608 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 609 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 610 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 611 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m38\u001b[0m in \u001b[92m_call_and_handle_interrupt\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m38 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m39 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m40 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m _TunerExitException:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m41 \u001b[0m\u001b[2m│   │   \u001b[0mtrainer._call_teardown_hook()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m650\u001b[0m in \u001b[92m_fit_impl\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 647 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_provided=\u001b[94mTrue\u001b[0m,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 648 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_connected=\u001b[96mself\u001b[0m.lightning_module \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 649 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 650 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._run(model, ckpt_path=\u001b[96mself\u001b[0m.ckpt_path)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 651 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 652 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.state.stopped                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 653 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training = \u001b[94mFalse\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mtrainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1048\u001b[0m in \u001b[92m_run\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1045 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# SET UP TRAINING\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1046 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1047 \u001b[0m\u001b[2m│   │   \u001b[0mlog.detail(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m: setting up strategy environment\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1048 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy.setup_environment()                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1049 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.__setup_profiler()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1050 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1051 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._call_setup_hook()  \u001b[2m# allow user to setup lightning_module in accelerator e\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mstrategies/\u001b[0m\u001b[1;33mstrategy.py\u001b[0m:\u001b[94m131\u001b[0m in \u001b[92msetup_environment\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33menvironment before setup is complete.\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.accelerator \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m131 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.setup_device(\u001b[96mself\u001b[0m.root_device)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup_optimizers\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Creates optimizers and schedulers.\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/pytorch/\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33maccelerators/\u001b[0m\u001b[1;33mcuda.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92msetup_device\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m MisconfigurationException(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mDevice should be GPU, got \u001b[0m\u001b[33m{\u001b[0mdevice\u001b[33m}\u001b[0m\u001b[33m instead\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 43 \u001b[2m│   │   \u001b[0m_check_cuda_matmul_precision(device)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   \u001b[0mtorch.cuda.set_device(device)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup\u001b[0m(\u001b[96mself\u001b[0m, trainer: \u001b[33m\"\u001b[0m\u001b[33mpl.Trainer\u001b[0m\u001b[33m\"\u001b[0m) -> \u001b[94mNone\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/lightning/fabric/a\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33mccelerators/\u001b[0m\u001b[1;33mcuda.py\u001b[0m:\u001b[94m246\u001b[0m in \u001b[92m_check_cuda_matmul_precision\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m243 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m _TORCH_GREATER_EQUAL_1_12:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m244 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# before 1.12, tf32 was used by default\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m245 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m246 \u001b[2m│   \u001b[0mmajor, _ = torch.cuda.get_device_capability(device)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   \u001b[0mampere_or_later = major >= \u001b[94m8\u001b[0m  \u001b[2m# Ampere and later leverage tensor cores, where this s\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m ampere_or_later:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/\u001b[0m\u001b[1;33m__init_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m_.py\u001b[0m:\u001b[94m357\u001b[0m in \u001b[92mget_device_capability\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m354 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m355 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mtuple(int, int): the major and minor cuda capability of the device\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m357 \u001b[2m│   \u001b[0mprop = get_device_properties(device)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m prop.major, prop.minor                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m359 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m360 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/\u001b[0m\u001b[1;33m__init_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m_.py\u001b[0m:\u001b[94m371\u001b[0m in \u001b[92mget_device_properties\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m_CudaDeviceProperties: the properties of the device\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m370 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m371 \u001b[2m│   \u001b[0m_lazy_init()  \u001b[2m# will define _get_device_properties\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   \u001b[0mdevice = _get_device_index(device, optional=\u001b[94mTrue\u001b[0m)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m device < \u001b[94m0\u001b[0m \u001b[95mor\u001b[0m device >= device_count():                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m374 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAssertionError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mInvalid device id\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages/torch/cuda/\u001b[0m\u001b[1;33m__init_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m_.py\u001b[0m:\u001b[94m229\u001b[0m in \u001b[92m_lazy_init\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# are found or any other error occurs\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mCUDA_MODULE_LOADING\u001b[0m\u001b[33m'\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m os.environ:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2m│   │   │   \u001b[0mos.environ[\u001b[33m'\u001b[0m\u001b[33mCUDA_MODULE_LOADING\u001b[0m\u001b[33m'\u001b[0m] = \u001b[33m'\u001b[0m\u001b[33mLAZY\u001b[0m\u001b[33m'\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m229 \u001b[2m│   │   \u001b[0mtorch._C._cuda_init()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# we need to just return without initializing in that case.\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m232 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# However, we must not let any *other* threads in!\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCUDA driver initialization failed, you might not have a CUDA gpu.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.tuner.tuning import Tuner\n",
    "\n",
    "tuner = Tuner(trainer)\n",
    "tuner.lr_find(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = get_linear_schedule_with_warmup(None, 100, 1000, min_lr_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, min_lr_ratio:float, last_epoch=-1):\n",
    "    def lr_lambda(current_step: int):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return (1-min_lr_ratio) / num_warmup_steps * float(current_step) + min_lr_ratio\n",
    "        return max(\n",
    "            min_lr_ratio, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps)) * (1-min_lr_ratio) + min_lr_ratio\n",
    "        )\n",
    "\n",
    "    return lr_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820000000000001"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch(910)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(0, 1000)\n",
    "y = [sch(i) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fedf0197490>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c519cf2c6da2821a5ede14ef8c95518e79ed282b9e31037d38b8ad55bc62ca50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
