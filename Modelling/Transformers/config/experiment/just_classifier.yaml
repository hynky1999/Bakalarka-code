# @package _global_
batch_size: 128
effective_batch_size: 128

optimizer:
  weight_decay: 0
  lr: 1e-3
scheduler:
  num_warmup_steps_classifier: 0
  total_unfreezes: 0
  min_lr_classifier: 1e-5



callbacks:
  - _target_: callbacks.GradualUnfreezingCallback
    unfreeze_per_epoch: 0
    min_unfreeze_layer: 12

defaults:
  - override /data: news_tokenized
  - override /scheduler: linear_for_freezing
  - override /optimizer: adamW
  - override /model: robeczech_class

max_epochs: 1
val_check_interval: 0.05
limit_val_batches: 0.0625
limit_train_batches: 0.5