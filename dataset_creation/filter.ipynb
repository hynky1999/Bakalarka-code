{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date \n",
    "\n",
    "folder =  Path(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(folder.absolute().as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocess_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_jsonb, save_jsonb \n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlparse\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m art \u001b[39min\u001b[39;00m load_jsonb(\u001b[39m\"\u001b[39m\u001b[39mfinal.jsonb\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/lnet/aic/personal/kydliceh/Articles_Analysis/dataset_creation/preprocess_utils.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m names \u001b[39m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maktualne\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdenik\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mseznamzpravy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[39m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m is_numpy_dev \u001b[39mas\u001b[39;00m _is_numpy_dev  \u001b[39m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m hashtable \u001b[39mas\u001b[39;00m _hashtable, lib \u001b[39mas\u001b[39;00m _lib, tslib \u001b[39mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyarrow\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[39m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decorators\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhashing\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperties\u001b[39;00m \u001b[39mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_exceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNaT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNaTType\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mInterval\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterval\u001b[39;00m \u001b[39mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/hashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/missing.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/tslibs/__init__.py:37\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdtypes\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlocalize_pydatetime\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_supported_unit\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m ]\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconversion\u001b[39;00m \u001b[39mimport\u001b[39;00m localize_pydatetime\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     Resolution,\n\u001b[1;32m     40\u001b[0m     is_supported_unit,\n\u001b[1;32m     41\u001b[0m     periods_per_day,\n\u001b[1;32m     42\u001b[0m     periods_per_second,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnattype\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     NaT,\n\u001b[1;32m     46\u001b[0m     NaTType,\n\u001b[1;32m     47\u001b[0m     iNaT,\n\u001b[1;32m     48\u001b[0m     nat_strings,\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from preprocess_utils import load_jsonb, save_jsonb \n",
    "from urllib.parse import urlparse\n",
    "for art in load_jsonb(\"final.jsonb\"):\n",
    "    url = art[\"url\"]\n",
    "    parsed = urlparse(url).netloc.split(\".\")\n",
    "    server = parsed[-1]\n",
    "    if server == \"cz\":\n",
    "        server = parsed[-2]\n",
    "\n",
    "    save_jsonb([art], folder / f\"{server}.jsonb\", \"a\", show_progress=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add from cz:403 to aktualne becauose of the same domain\n",
    "\n",
    "# for art in load_jsonb(folder / \"cz:443.jsonb\"):\n",
    "#     save_jsonb([art], folder / \"aktualne.jsonb\", \"a\", show_progress=False)\n",
    "\n",
    "# Remove cz:443\n",
    "import os\n",
    "os.remove(folder / \"cz:443.jsonb\")\n",
    "os.remove(folder / \"ihned.jsonb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ihned.jsonb', 31643), ('aktualne.jsonb', 165799), ('cz:443.jsonb', 1), ('denik.jsonb', 1636639), ('irozhlas.jsonb', 201681), ('novinky.jsonb', 549661), ('idnes.jsonb', 530855), ('seznamzpravy.jsonb', 77442)]\n"
     ]
    }
   ],
   "source": [
    "from preprocess_utils import articles_num\n",
    "print(list(articles_num(folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_cat = [\n",
    "    ([\"zprávy z domova\", \"z domova\", \"domov\"], \"domácí\"),\n",
    "    ([\"zprávy ze světa\", \"svět\", \"zahraničí\", \"ze světa\"], \"zahraniční\"),\n",
    "    ([\"ona\", \"ženy\", \"pro ženy\"], \"žena\"),\n",
    "    (\n",
    "        [\"tipy deníku\", \"rádce\", \"rady učitele\", \"eko rady a tipy\"],\n",
    "        \"tipy\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"nepoužívat - věda\",\n",
    "            \"věda a školy\",\n",
    "            \"věda a technologie\",\n",
    "            \"věda a technika\",\n",
    "            \"věda a vesmír\",\n",
    "            \"věda a příroda\",\n",
    "            \"věda & vesmír\"\n",
    "        ],\n",
    "        \"věda\",\n",
    "    ),\n",
    "    (\n",
    "        [\"technet\", \"tech & trendy\", \"tech\", \"technika\"],\n",
    "        \"technologie\",\n",
    "    ),\n",
    "    (\n",
    "        [\"osobní finance\"],\n",
    "        \"finance\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"nová auta\",\n",
    "            \"automoto\",\n",
    "            \"motorismus\",\n",
    "            \"auta\",\n",
    "            \"moje auto\",\n",
    "            \"auta a motorky\",\n",
    "            \"motocykly\",\n",
    "            \"autohistorie\",\n",
    "        ],\n",
    "        \"auto\",\n",
    "    ),\n",
    "    (\n",
    "        [\"televize\", \"film\", \"tv\"],\n",
    "        \"film a tv\",\n",
    "    ),\n",
    "    ([\"lidé\"], \"člověk\"),\n",
    "    (\n",
    "        [\"na kole po česku\", \"cyklorady\", \"cyklotrasy\"],\n",
    "        \"kolo\",\n",
    "    ),\n",
    "    (\n",
    "        [\"cestovánía dovolená\", \"po česku\", \"cestujeme\"],\n",
    "        \"cestování\",\n",
    "    ),\n",
    "    (\n",
    "        [\"rady a zajímavosti\"],\n",
    "        \"zajímavosti\",\n",
    "    ),\n",
    "    ([\"životní styl a společnost\", \"styl\", \"životnístyl\"], \"životní styl\"),\n",
    "    ([\"zdraví\", \"zdraví a fitness\", \"fit\"], \"zdraví\"),\n",
    "    ([\"nepouzivat - kultura\"], \"kultura\"),\n",
    "    ([\"jídelníček a recepty\"], \"recepty\"),\n",
    "    ([\"nepouzivat - kultura\", \"tipy na kulturu\", \"tipyna kulturu\"], \"kultura\"),\n",
    "    ([\"internet a pc\"], \"internet\"),\n",
    "    ([\"česká ekonomika\", \"světová ekonomika\"], \"ekonomika\"),\n",
    "    ([\"práce a podnikání\", \"podniky\"], \"podnikání\"),\n",
    "    ([\"hokej\", \"ms v hokeji\", \"ms hokej\", \"vancouver - hokej\", \"nhl\", \"extraliga\"], \"hokej\"),\n",
    "    ([\"kraje\", \"regiony\"], \"regiony\"),\n",
    "    ([\"ms ve fotbale\", \"česká liga\", \"liga mistrů\", \"evropská liga\"], \"fotbal\"),\n",
    "    (\n",
    "        [\n",
    "            \"moje praha\",\n",
    "            \"praha a střední čechy\",\n",
    "        ],\n",
    "        \"praha\",\n",
    "    ),\n",
    "    ([\"klasická hudba\"], \"hudba\"),\n",
    "    ([\"basket\"], \"basketbal\"),\n",
    "    ([\"mobily\", \"telefony\"], \"mobil\"),\n",
    "    ([\"názory\"], \"komentáře\"),\n",
    "    ([\"loh 2020\", \"loh 2016 rio de janeiro\", \"tokio 2021\", \"tokio 2020\", \"loh 2012 londýn\"], \"olympijské hry\"),\n",
    "]\n",
    "\n",
    "\n",
    "translate_cat = dict(\n",
    "    [(x, y) for items, res in translate_cat for x, y in zip(items, [res] * len(items))]\n",
    ")\n",
    "\n",
    "with open(\"categories.txt\") as f:\n",
    "    cats = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /lnet/aic/personal/kydliceh/non_runable/NLP_venv/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/lnet/aic/personal/kydliceh/non_runable/NLP_venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Callable, List\n",
    "from filtering import create_filter_by_stats, create_filter_by_cz_lang, create_config, create_tokenized_filter\n",
    "from preprocess_utils import load_jsonb, save_jsonb\n",
    "from postprocessing_utils import postprocess_authors, filter_author, add_server, translate, filter_by_list, postprocess_brief, postprocess_category, postprocess_headline, postprocess_date, as_Article,JSONArticleEncoder, filter_by_list, add_cum_gender\n",
    "filtered_folder = Path(\"article_json_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom config for each server\n",
    "from filtering import between\n",
    "configs = {\n",
    "    \"idnes\": {},\n",
    "    \"denik\": {},\n",
    "    \"aktualne\": {},\n",
    "    \"irozhlas\": {},\n",
    "    \"seznamzpravy\": {},\n",
    "    \"novinky\": {},\n",
    "}\n",
    "\n",
    "default = {\n",
    "    \"article_length\": between(300, None),\n",
    "    \"avg_word_length\": between(4.0, None),\n",
    "    \"num_words_ratio\": between(0.11, 0.22),\n",
    "    \"headline_length\": between(20, None),\n",
    "    \"brief_length\": between(40, None),\n",
    "    \"non_alpha_ratio\": between(None, 0.045),\n",
    "    \"date\": between(date(2000, 1, 1), date(2022, 8, 31)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77442/77442 [03:14<00:00, 397.71it/s]\n",
      "100%|██████████| 1636639/1636639 [55:27<00:00, 491.84it/s]\n",
      "100%|██████████| 530855/530855 [17:27<00:00, 506.84it/s]\n",
      "100%|██████████| 201681/201681 [05:54<00:00, 568.53it/s]\n",
      "100%|██████████| 549661/549661 [12:40<00:00, 723.22it/s]\n",
      "100%|██████████| 165798/165798 [06:36<00:00, 418.18it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import reduce\n",
    "servers = [f for f in folder.iterdir()]\n",
    "\n",
    "ratio = 0.75\n",
    "for f in servers:\n",
    "    filters = [\n",
    "        create_filter_by_cz_lang(),\n",
    "        create_filter_by_stats(create_config(configs[f.stem], default)),\n",
    "    ]\n",
    "\n",
    "    augmentations = [add_server(f.stem), filter_author,\n",
    "    translate(\"category\", translate_cat, lower=True),\n",
    "    filter_by_list(\"category\", cats, lower=True),\n",
    "    postprocess_category,postprocess_authors, postprocess_brief, postprocess_headline, postprocess_date, add_cum_gender]\n",
    "\n",
    "\n",
    "    articles = load_jsonb(f)\n",
    "    articles = filter(lambda x: all(f(x) for f in filters), articles)\n",
    "\n",
    "\n",
    "    articles = (reduce(lambda x, f: f(x), augmentations, article) for article in articles)\n",
    "    \n",
    "\n",
    "\n",
    "    as_articles = (as_Article(article) for article in articles)\n",
    "    save_jsonb(as_articles, Path(\"test\") / f\"{f.stem}.jsonb\", encoder=JSONArticleEncoder, show_progress=False)\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67378/67378 [00:09<00:00, 7056.26it/s]\n",
      "100%|██████████| 314479/314479 [00:42<00:00, 7383.48it/s]\n",
      "100%|██████████| 172151/172151 [00:23<00:00, 7351.19it/s] \n",
      "100%|██████████| 118210/118210 [00:14<00:00, 8427.12it/s]\n",
      "100%|██████████| 1185135/1185135 [03:04<00:00, 6428.95it/s]\n",
      "100%|██████████| 371566/371566 [00:33<00:00, 11059.28it/s]\n",
      "100%|██████████| 1781963/1781963 [03:06<00:00, 9559.96it/s]\n",
      "100%|██████████| 222745/222745 [00:26<00:00, 8565.62it/s]\n",
      "100%|██████████| 222746/222746 [00:26<00:00, 8385.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create splits 70/20/10 by date\n",
    "from datetime import date\n",
    "import random\n",
    "output_folder = Path(\"../final_dataset\")\n",
    "servers = [f for f in filtered_folder.iterdir()]\n",
    "#servers = [fixed_folder / \"seznamzpravy.jsonb\"]\n",
    "\n",
    "all_articles = (article for f in servers for article in load_jsonb(f))\n",
    "none_articles = (article for article in all_articles if article[\"date\"] is None)\n",
    "articles = (article for article in all_articles if article[\"date\"] is not None)\n",
    "sorted_articles = sorted(articles, key=lambda x: date.fromisoformat(x[\"date\"]))\n",
    "# Randomly insert none articles\n",
    "for none_art in none_articles:\n",
    "    index = random.randint(0, len(sorted_articles))\n",
    "    sorted_articles.insert(index, none_art)\n",
    "\n",
    "train = sorted_articles[:int(len(sorted_articles) * 0.8)]\n",
    "dev = sorted_articles[int(len(sorted_articles) * 0.8):int(len(sorted_articles) * 0.9)]\n",
    "test = sorted_articles[int(len(sorted_articles) * 0.9):]\n",
    "\n",
    "save_jsonb(train, output_folder / \"train.jsonb\", show_progress=True)\n",
    "save_jsonb(dev, output_folder / \"dev.jsonb\", show_progress=True)\n",
    "save_jsonb(test, output_folder / \"test.jsonb\", show_progress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from preprocess_utils import load_jsonb, save_jsonb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1783006/1783006 [04:07<00:00, 7213.51it/s] \n",
      "100%|██████████| 222876/222876 [00:29<00:00, 7587.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in Path(\"../final_dataset/\").iterdir():\n",
    "    jss = []\n",
    "    for js in load_jsonb(file):\n",
    "        author_gen = js[\"author_genders\"]\n",
    "        gen_t = None\n",
    "        if author_gen is not None:\n",
    "            author_gen = [int(x) - 1 for x in author_gen]\n",
    "            if all([a == 0 for a in author_gen]):\n",
    "                gen_t = 0\n",
    "            elif all([a == 1 for a in author_gen]):\n",
    "                gen_t = 1\n",
    "            else:\n",
    "                gen_t = 2\n",
    "            \n",
    "        del(js[\"author_genders\"])\n",
    "        js[\"authors_gender\"] = author_gen\n",
    "        js[\"cum_gender\"] = gen_t\n",
    "        jss += [js]\n",
    "    save_jsonb(jss, Path(\"../final\") / f\"{file.stem}.jsonb\", show_progress=False)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16cbb3c1b98e7ff9e9084c08b6a46066910048fd1e72dd127d27daf6d44bc88d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
