{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1671623219024 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd dataset_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date \n",
    "\n",
    "folder =  Path(\"dataset_creation\") / \"base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3193720/3193720 [1:33:08<00:00, 571.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from preprocess_utils import load_jsonb, save_jsonb \n",
    "from urllib.parse import urlparse\n",
    "for art in load_jsonb(\"final.jsonb\"):\n",
    "    url = art[\"url\"]\n",
    "    parsed = urlparse(url).netloc.split(\".\")\n",
    "    server = parsed[-1]\n",
    "    if server == \"cz\":\n",
    "        server = parsed[-2]\n",
    "\n",
    "    save_jsonb([art], folder / f\"{server}.jsonb\", \"a\", show_progress=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add from cz:403 to aktualne becauose of the same domain\n",
    "\n",
    "# for art in load_jsonb(folder / \"cz:443.jsonb\"):\n",
    "#     save_jsonb([art], folder / \"aktualne.jsonb\", \"a\", show_progress=False)\n",
    "\n",
    "# Remove cz:443\n",
    "import os\n",
    "os.remove(folder / \"cz:443.jsonb\")\n",
    "os.remove(folder / \"ihned.jsonb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ihned.jsonb', 31643), ('aktualne.jsonb', 165799), ('cz:443.jsonb', 1), ('denik.jsonb', 1636639), ('irozhlas.jsonb', 201681), ('novinky.jsonb', 549661), ('idnes.jsonb', 530855), ('seznamzpravy.jsonb', 77442)]\n"
     ]
    }
   ],
   "source": [
    "from preprocess_utils import articles_num\n",
    "print(list(articles_num(folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable, List\n",
    "from filtering import create_filter_by_stats, create_filter_by_cz_lang, create_config, create_tokenized_filter\n",
    "from preprocess_utils import load_jsonb, save_jsonb\n",
    "from postprocessing_utils import postprocess_authors, filter_author, add_server, postprocess_brief, postprocess_category, postprocess_headline, postprocess_date, as_Article, LowerTopXWhiten ,JSONArticleEncoder\n",
    "filtered_folder = Path(\"article_json_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Custom config for each server\n",
    "from filtering import between\n",
    "configs = {\n",
    "    \"idnes\": {},\n",
    "    \"denik\": {},\n",
    "    \"aktualne\": {},\n",
    "    \"irozhlas\": {},\n",
    "    \"seznamzpravy\": {},\n",
    "    \"novinky\": {},\n",
    "}\n",
    "\n",
    "default = {\n",
    "    \"article_length\": between(300, None),\n",
    "    \"avg_word_length\": between(4.0, None),\n",
    "    \"num_words_ratio\": between(0.11, 0.22),\n",
    "    \"headline_length\": between(20, None),\n",
    "    \"brief_length\": between(40, None),\n",
    "    \"non_alpha_ratio\": between(None, 0.045),\n",
    "    \"date\": between(date(2000, 1, 1), date(2022, 8, 31)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1636639/1636639 [1:56:57<00:00, 233.21it/s]\n",
      "100%|██████████| 201681/201681 [14:02<00:00, 239.44it/s]\n",
      "100%|██████████| 549661/549661 [28:05<00:00, 326.18it/s]\n",
      "100%|██████████| 530855/530855 [37:59<00:00, 232.91it/s]\n",
      "100%|██████████| 77442/77442 [06:41<00:00, 192.84it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import reduce\n",
    "servers = [f for f in folder.iterdir()]\n",
    "\n",
    "ratio = 0.75\n",
    "for f in servers:\n",
    "    filters = [\n",
    "        #TODO run without tokenized filter\n",
    "        create_filter_by_cz_lang(),\n",
    "        create_filter_by_stats(create_config(configs[f.stem], default)),\n",
    "        create_tokenized_filter(lambda x: len(x) <= 4, \"category\"),\n",
    "        # Max 4 words in category\n",
    "    ]\n",
    "\n",
    "    augmentations: List[Callable[[dict], dict]] = [add_server(f.stem), filter_author, postprocess_authors, postprocess_brief, postprocess_category, postprocess_headline, postprocess_date]\n",
    "\n",
    "\n",
    "    articles = load_jsonb(f)\n",
    "    articles = filter(lambda x: all(f(x) for f in filters), articles)\n",
    "\n",
    "\n",
    "    #TODO Apply as df filters as could be faster    \n",
    "    articles = (reduce(lambda x, f: f(x), augmentations, article) for article in articles)\n",
    "    \n",
    "\n",
    "\n",
    "    as_articles = (as_Article(article) for article in articles)\n",
    "    save_jsonb(as_articles, filtered_folder / f\"{f.stem}.jsonb\", encoder=JSONArticleEncoder, show_progress=False)\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('seznamzpravy.jsonb', 67378), ('idnes.jsonb', 314479), ('irozhlas.jsonb', 172151), ('aktualne.jsonb', 118210), ('denik.jsonb', 1185135), ('novinky.jsonb', 371566)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from preprocess_utils import articles_num\n",
    "print(list(articles_num(filtered_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67378/67378 [00:09<00:00, 7056.26it/s]\n",
      "100%|██████████| 314479/314479 [00:42<00:00, 7383.48it/s]\n",
      "100%|██████████| 172151/172151 [00:23<00:00, 7351.19it/s] \n",
      "100%|██████████| 118210/118210 [00:14<00:00, 8427.12it/s]\n",
      "100%|██████████| 1185135/1185135 [03:04<00:00, 6428.95it/s]\n",
      "100%|██████████| 371566/371566 [00:33<00:00, 11059.28it/s]\n",
      "100%|██████████| 1781963/1781963 [03:06<00:00, 9559.96it/s]\n",
      "100%|██████████| 222745/222745 [00:26<00:00, 8565.62it/s]\n",
      "100%|██████████| 222746/222746 [00:26<00:00, 8385.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create splits 70/20/10 by date\n",
    "from datetime import date\n",
    "import random\n",
    "output_folder = Path(\"final_dataset\")\n",
    "servers = [f for f in filtered_folder.iterdir()]\n",
    "#servers = [fixed_folder / \"seznamzpravy.jsonb\"]\n",
    "\n",
    "all_articles = (article for f in servers for article in load_jsonb(f))\n",
    "none_articles = (article for article in all_articles if article[\"date\"] is None)\n",
    "articles = (article for article in all_articles if article[\"date\"] is not None)\n",
    "sorted_articles = sorted(articles, key=lambda x: date.fromisoformat(x[\"date\"]))\n",
    "# Randomly insert none articles\n",
    "for none_art in none_articles:\n",
    "    index = random.randint(0, len(sorted_articles))\n",
    "    sorted_articles.insert(index, none_art)\n",
    "\n",
    "train = sorted_articles[:int(len(sorted_articles) * 0.8)]\n",
    "dev = sorted_articles[int(len(sorted_articles) * 0.8):int(len(sorted_articles) * 0.9)]\n",
    "test = sorted_articles[int(len(sorted_articles) * 0.9):]\n",
    "\n",
    "save_jsonb(train, output_folder / \"train.jsonb\", show_progress=True)\n",
    "save_jsonb(dev, output_folder / \"dev.jsonb\", show_progress=True)\n",
    "save_jsonb(test, output_folder / \"test.jsonb\", show_progress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16cbb3c1b98e7ff9e9084c08b6a46066910048fd1e72dd127d27daf6d44bc88d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
