{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date \n",
    "\n",
    "folder =  Path(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(folder.absolute().as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocess_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_jsonb, save_jsonb \n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlparse\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m art \u001b[39min\u001b[39;00m load_jsonb(\u001b[39m\"\u001b[39m\u001b[39mfinal.jsonb\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/lnet/aic/personal/kydliceh/Articles_Analysis/dataset_creation/preprocess_utils.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m names \u001b[39m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maktualne\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdenik\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mseznamzpravy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[39m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m is_numpy_dev \u001b[39mas\u001b[39;00m _is_numpy_dev  \u001b[39m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m hashtable \u001b[39mas\u001b[39;00m _hashtable, lib \u001b[39mas\u001b[39;00m _lib, tslib \u001b[39mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyarrow\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[39m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decorators\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhashing\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproperties\u001b[39;00m \u001b[39mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_exceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNaT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNaTType\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mInterval\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterval\u001b[39;00m \u001b[39mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/hashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/missing.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Articles_Analysis/venv/lib/python3.10/site-packages/pandas/_libs/tslibs/__init__.py:37\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdtypes\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlocalize_pydatetime\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_supported_unit\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m ]\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconversion\u001b[39;00m \u001b[39mimport\u001b[39;00m localize_pydatetime\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     Resolution,\n\u001b[1;32m     40\u001b[0m     is_supported_unit,\n\u001b[1;32m     41\u001b[0m     periods_per_day,\n\u001b[1;32m     42\u001b[0m     periods_per_second,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtslibs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnattype\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     NaT,\n\u001b[1;32m     46\u001b[0m     NaTType,\n\u001b[1;32m     47\u001b[0m     iNaT,\n\u001b[1;32m     48\u001b[0m     nat_strings,\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from preprocess_utils import load_jsonb, save_jsonb \n",
    "from datasets import Dataset\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "for art in load_jsonb(\"final.jsonb\"):\n",
    "    url = art[\"url\"]\n",
    "    parsed = urlparse(url).netloc.split(\".\")\n",
    "    server = parsed[-1]\n",
    "    if server == \"cz\":\n",
    "        server = parsed[-2]\n",
    "\n",
    "    save_jsonb([art], folder / f\"{server}.jsonb\", \"a\", show_progress=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add from cz:403 to aktualne becauose of the same domain\n",
    "\n",
    "# for art in load_jsonb(folder / \"cz:443.jsonb\"):\n",
    "#     save_jsonb([art], folder / \"aktualne.jsonb\", \"a\", show_progress=False)\n",
    "\n",
    "# Remove cz:443\n",
    "import os\n",
    "os.remove(folder / \"cz:443.jsonb\")\n",
    "os.remove(folder / \"ihned.jsonb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('seznamzpravy.jsonb', 77442), ('denik.jsonb', 1636639), ('idnes.jsonb', 530855), ('irozhlas.jsonb', 201681), ('novinky.jsonb', 549661), ('aktualne.jsonb', 165798)]\n"
     ]
    }
   ],
   "source": [
    "from preprocess_utils import articles_num\n",
    "print(list(articles_num(folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_cat = [\n",
    "    ([\"zprávy z domova\", \"z domova\", \"domov\"], \"domácí\"),\n",
    "    ([\"zprávy ze světa\", \"svět\", \"zahraničí\", \"ze světa\"], \"zahraniční\"),\n",
    "    (\n",
    "        [\"tipy deníku\", \"rádce\", \"rady učitele\", \"eko rady a tipy\"],\n",
    "        \"tipy\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"nepoužívat - věda\",\n",
    "            \"věda a školy\",\n",
    "            \"věda a technologie\",\n",
    "            \"věda a technika\",\n",
    "            \"věda a vesmír\",\n",
    "            \"věda a příroda\",\n",
    "            \"věda & vesmír\",\n",
    "            \"vesmír\",\n",
    "        ],\n",
    "        \"věda\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"technet\",\n",
    "            \"tech & trendy\",\n",
    "            \"tech\",\n",
    "            \"technika\",\n",
    "            \"hardware\",\n",
    "            \"software\",\n",
    "            \"internet\",\n",
    "            \"web\",\n",
    "            \"internet a pc\",\n",
    "            \"aplikace\",\n",
    "            \"bonusweb\",\n",
    "            \"plné hry\",\n",
    "        ],\n",
    "        \"technologie\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"osobní finance\",\n",
    "            \"hypotéky a půjčky\",\n",
    "            \"banky a spoření\",\n",
    "            \"pojištení\",\n",
    "            \"investice\",\n",
    "            \"daně\",\n",
    "            \"penze\",\n",
    "        ],\n",
    "        \"finance\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"nová auta\",\n",
    "            \"automoto\",\n",
    "            \"motorismus\",\n",
    "            \"auta\",\n",
    "            \"moje auto\",\n",
    "            \"auta a motorky\",\n",
    "            \"motocykly\",\n",
    "            \"autohistorie\",\n",
    "            \"ojetá auta\",\n",
    "            \"život řidiče\",\n",
    "            \"motorky\",\n",
    "        ],\n",
    "        \"auto\",\n",
    "    ),\n",
    "    (\n",
    "        [\"televize\", \"film\", \"tv\", \"film a tv\"],\n",
    "        \"kultura\",\n",
    "    ),\n",
    "    ([\"lidé\"], \"člověk\"),\n",
    "    (\n",
    "        [\"na kole po česku\", \"cyklorady\", \"cyklotrasy\"],\n",
    "        \"kolo\",\n",
    "    ),\n",
    "    ([\"stavba\", \"bydlení\", \"koupelna\", \"kuchyně\"], \"bydlení\"),\n",
    "    (\n",
    "        [\"cestovánía dovolená\", \"po česku\", \"cestujeme\"],\n",
    "        \"cestování\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"životní styl a společnost\",\n",
    "            \"ona\",\n",
    "            \"žena\",\n",
    "            \"ženy\",\n",
    "            \"pro ženy\" \"styl\",\n",
    "            \"životnístyl\",\n",
    "            \"nakupování\",\n",
    "            \"nákupy\",\n",
    "            \"móda\",\n",
    "            \"vztahy\",\n",
    "            \"vztahy a sex\",\n",
    "            \"sex\",\n",
    "        ],\n",
    "        \"životní styl\",\n",
    "    ),\n",
    "    ([\"zdraví\", \"zdraví a fitness\", \"fit\", \"krása\"], \"životní styl\"),\n",
    "    ([\"jídelníček a recepty\", \"recepty\"], \"životní styl\"),\n",
    "    (\n",
    "        [\"nepouzivat - kultura\", \"tipy na kulturu\", \"tipyna kulturu\", \"divadlo\"],\n",
    "        \"kultura\",\n",
    "    ),\n",
    "    ([\"česká ekonomika\", \"světová ekonomika\"], \"ekonomika\"),\n",
    "    ([\"práce a podnikání\", \"podniky\", \"byznys\", \"aktuálně o eet\"], \"byznys\"),\n",
    "    (\n",
    "        [\"hokej\", \"ms v hokeji\", \"ms hokej\", \"vancouver - hokej\", \"nhl\", \"extraliga\"],\n",
    "        \"sport\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"kraje\",\n",
    "            \"regiony\",\n",
    "            \"z okolí\",\n",
    "            \"praha\",\n",
    "            \"brněnsko\",\n",
    "            \"blanensko\",\n",
    "            \"Českobudějovicko\",\n",
    "            \"chebsko\",\n",
    "            \"berounsko\",\n",
    "            \"děčínsko\",\n",
    "            \"bruntálsko\",\n",
    "            \"Boleslavsko\",\n",
    "            \"Hradecko\",\n",
    "            \"Českolipsko\",\n",
    "            \"Havlíčkobrodsko\",\n",
    "            \"Břeclavsko\",\n",
    "            \"Domažlicko\",\n",
    "            \"Chrudimsko\",\n",
    "            \"Litoměřicko\",\n",
    "            \"Ústecko\",\n",
    "            \"Karlovarsko\",\n",
    "            \"Benešovsko\",\n",
    "            \"Chomutovsko\",\n",
    "            \"Liberecko\",\n",
    "            \"Frýdecko-místecko\",\n",
    "            \"Českokrumlovsko\",\n",
    "            \"Hranicko\",\n",
    "            \"Žďársko\",\n",
    "            \"Olomoucko\",\n",
    "            \"Hodonínsko\",\n",
    "            \"Prachaticko\",\n",
    "            \"Krkonoše\",\n",
    "            \"Jindřichohradecko\",\n",
    "            \"Jihlavsko\",\n",
    "            \"Jablonecko\",\n",
    "            \"Ostravsko\",\n",
    "            \"Plzeňsko\",\n",
    "            \"Jihomoravský kraj\",\n",
    "            \"Jičínsko\",\n",
    "            \"Rakovnicko\",\n",
    "            \"Slovácko\",\n",
    "            \"Orlicko\",\n",
    "            \"Zlínsko\",\n",
    "            \"Nymbursko\",\n",
    "            \"Žatecko a lounsko\",\n",
    "            \"Prostějovsko\",\n",
    "            \"Ústecký kraj\",\n",
    "            \"Vyškovsko\",\n",
    "            \"Moravskoslezský kraj\",\n",
    "            \"Středočeský kraj\",\n",
    "            \"Písecko\",\n",
    "            \"Strakonicko\",\n",
    "            \"Tachovsko\",\n",
    "            \"Táborsko\",\n",
    "            \"Rokycansko\",\n",
    "            \"Klatovsko\",\n",
    "            \"Novojičínsko\",\n",
    "            \"Kladensko\",\n",
    "            \"Znojemsko\",\n",
    "            \"Kutnohorsko\",\n",
    "            \"Teplicko\",\n",
    "            \"Svitavsko\",\n",
    "            \"Kroměřížsko\",\n",
    "            \"Třebíčsko\",\n",
    "            \"Mostecko\",\n",
    "            \"Opavsko\",\n",
    "            \"Pardubicko\",\n",
    "            \"Přerovsko\",\n",
    "            \"Šumpersko\",\n",
    "            \"Kolínsko\",\n",
    "            \"Zlínský kraj\",\n",
    "            \"Sokolovsko\",\n",
    "            \"Příbramsko\",\n",
    "            \"Olomoucký kraj\",\n",
    "            \"Královéhradecký kraj\",\n",
    "            \"Liberecký kraj\",\n",
    "            \"Karvinsko\",\n",
    "            \"Valašsko\",\n",
    "            \"Pelhřimovsko\",\n",
    "            \"Pardubický kraj\",\n",
    "            \"Plzeňský kraj\",\n",
    "            \"Jihočeský kraj\",\n",
    "            \"Rychnovsko\",\n",
    "            \"Náchodsko\",\n",
    "            \"Kraj vysočina\",\n",
    "            \"Mělnicko\",\n",
    "            \"Karlovarský kraj\",\n",
    "        ],\n",
    "        \"domácí\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"ms ve fotbale\",\n",
    "            \"česká liga\",\n",
    "            \"liga mistrů\",\n",
    "            \"evropská liga\",\n",
    "            \"fotbal\",\n",
    "            \"euro 2016\",\n",
    "            \"euro\",\n",
    "        ],\n",
    "        \"sport\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"klasická hudba\",\n",
    "            \"hudba\",\n",
    "            \"mff kv 2010\",\n",
    "            \"mff kv 2011\",\n",
    "            \"mff kv 2012\",\n",
    "            \"mff kv 2014\",\n",
    "            \"mff kv 2015\",\n",
    "            \"mff kv 2016\",\n",
    "            \"mff kv 2017\",\n",
    "            \"mff kv 2018\",\n",
    "            \"mff kv 2019\",\n",
    "            \"mff kv\",\n",
    "        ],\n",
    "        \"kultura\",\n",
    "    ),\n",
    "    ([\"basket\", \"basketbal\"], \"sport\"),\n",
    "    ([\"mobily\", \"telefony\", \"mobil\"], \"technologie\"),\n",
    "    ([\"názory\"], \"komentáře\"),\n",
    "    (\n",
    "        [\n",
    "            \"loh 2020\",\n",
    "            \"loh 2016 rio de janeiro\",\n",
    "            \"tokio 2021\",\n",
    "            \"tokio 2020\",\n",
    "            \"loh 2012 londýn\",\n",
    "            \"peking 2022\",\n",
    "            \"vancouver - olympijské deníky\",\n",
    "        ],\n",
    "        \"sport\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            \"tenis\",\n",
    "            \"ostatní sporty\",\n",
    "            \"zahraniční ligy\",\n",
    "            \"atletika\",\n",
    "            \"reprezentace\",\n",
    "            \"formule 1\",\n",
    "            \"zimní sporty\",\n",
    "            \"lyže\",\n",
    "            \"tour de france\",\n",
    "            \"rallye\",\n",
    "            \"biatlon\",\n",
    "        ],\n",
    "        \"sport\",\n",
    "    ),\n",
    "    ([\"černá kronika\"], \"krimi\"),\n",
    "    # Domácí as all other politics are in domácí\n",
    "    ([\"volby\", \"politika\"], \"domácí\"),\n",
    "    ([\"koktejl\", \"kuriozity\", \"zajímavosti\", \"rady a zajímavosti\"], \"koktejl\"),\n",
    "    ([\"revue\", \"modelky\", \"celebrity\"], \"revue\"),\n",
    "    ([\"příběhy a rozhovory\", \"rozhovory\"], \"rozhovory\"),\n",
    "]\n",
    "\n",
    "\n",
    "translate_cat = dict(\n",
    "    [(x, y) for items, res in translate_cat for x, y in zip(items, [res] * len(items))]\n",
    ")\n",
    "\n",
    "with open(\"categories.txt\") as f:\n",
    "    cats = set(f.read().splitlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing_utils import Gender\n",
    "authors = {}\n",
    "with open(\"authors.txt\") as f:\n",
    "    for line in f:\n",
    "        author, gender = line.split(\",\")\n",
    "        gender = Gender.MAN if gender.strip() == \"male\" else Gender.WOMAN\n",
    "        authors[author] = gender\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"headline_filter.txt\") as f:\n",
    "    headline_filters = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_servers = list(folder.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable, List\n",
    "from filtering import create_filter_by_stats, create_filter_by_cz_lang, create_config, create_tokenized_filter, create_filter\n",
    "from preprocess_utils import load_jsonb, save_jsonb\n",
    "from postprocessing_utils import postprocess_authors, filter_author, add_server, translate, filter_by_set, postprocess_brief, postprocess_category, postprocess_headline, postprocess_date, postprocess_content  ,as_Article,JSONArticleEncoder, add_cum_gender, add_gender\n",
    "filtered_folder = Path(\"article_json_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom config for each server\n",
    "from filtering import between\n",
    "configs = {\n",
    "    \"idnes\": {},\n",
    "    \"denik\": {},\n",
    "    \"aktualne\": {},\n",
    "    \"irozhlas\": {},\n",
    "    \"seznamzpravy\": {},\n",
    "    \"novinky\": {},\n",
    "}\n",
    "\n",
    "default = {\n",
    "    \"article_length\": between(400, None),\n",
    "    \"avg_word_length\": between(4.0, None),\n",
    "    \"num_words_ratio\": between(0.11, 0.22),\n",
    "    \"headline_length\": between(20, None),\n",
    "    \"brief_length\": between(40, None),\n",
    "    \"non_alpha_ratio\": between(None, 0.045),\n",
    "    \"date\": between(date(2000, 1, 1), date(2022, 8, 31)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77442/77442 [03:32<00:00, 364.78it/s]\n",
      "100%|██████████| 1636639/1636639 [1:00:15<00:00, 452.69it/s]\n",
      "100%|██████████| 530855/530855 [18:30<00:00, 478.18it/s]\n",
      "100%|██████████| 201681/201681 [06:24<00:00, 524.62it/s]\n",
      "100%|██████████| 549661/549661 [13:48<00:00, 663.60it/s]\n",
      "100%|██████████| 165798/165798 [07:04<00:00, 390.86it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "ratio = 0.75\n",
    "for f in base_servers:\n",
    "    filters = [\n",
    "        create_filter_by_cz_lang(),\n",
    "        create_filter_by_stats(create_config(configs[f.stem], default)),\n",
    "        create_filter(\"headline\", headline_filters, lambda head,f: head.startswith(f)),\n",
    "    ]\n",
    "\n",
    "    augmentations = [add_server(f.stem),\n",
    "    translate(\"category\", translate_cat, lower=True),\n",
    "    postprocess_category, filter_by_set(\"category\", cats, lower=True), postprocess_authors, filter_by_set(\"author\", set(authors.keys()), lower=True),postprocess_brief, postprocess_headline, postprocess_content, postprocess_date, add_gender(authors), add_cum_gender]\n",
    "\n",
    "\n",
    "    articles = load_jsonb(f)\n",
    "    articles = filter(lambda x: all(f(x) for f in filters), articles)\n",
    "\n",
    "\n",
    "    articles = (reduce(lambda x, f: f(x), augmentations, article) for article in articles)\n",
    "    \n",
    "\n",
    "\n",
    "    as_articles = (as_Article(article) for article in articles)\n",
    "    save_jsonb(as_articles, filtered_folder / f\"{f.stem}.jsonb\", encoder=JSONArticleEncoder, show_progress=False)\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_duplicate_folder = Path(\"no_duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301874/301874 [00:39<00:00, 7559.36it/s] \n",
      "100%|██████████| 168151/168151 [00:07<00:00, 21784.30it/s]\n",
      "100%|██████████| 363108/363108 [00:15<00:00, 23411.09it/s]\n",
      "100%|██████████| 66160/66160 [00:03<00:00, 18632.71it/s]\n",
      "100%|██████████| 115273/115273 [00:06<00:00, 16880.20it/s]\n",
      "100%|██████████| 1109550/1109550 [01:28<00:00, 12560.90it/s]\n",
      "100%|██████████| 2124116/2124116 [00:19<00:00, 109446.09it/s]\n",
      "100%|██████████| 1628645/1628645 [01:20<00:00, 20183.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "UNIQ_COLS = [\"headline\", \"brief\", \"content\"]\n",
    "uniq_dicts = {cat: dict() for cat in UNIQ_COLS}\n",
    "\n",
    "\n",
    "\n",
    "servers = [f for f in filtered_folder.iterdir()]\n",
    "all_articles = (article for f in servers for article in load_jsonb(f))\n",
    "\n",
    "articles = sorted(all_articles, key=lambda x: sum(map(lambda val: val != None, x.values())), reverse=True)\n",
    "aritcles = sorted(articles, key=lambda x: len(x[\"content\"]), reverse=True)\n",
    "app_articles = []\n",
    "for article in tqdm(articles):\n",
    "    append = True\n",
    "    for col in UNIQ_COLS:\n",
    "        retrived = article[col]\n",
    "        if retrived == None:\n",
    "            continue\n",
    "\n",
    "        if retrived in uniq_dicts[col]:\n",
    "            uniq_dicts[col][retrived] += 1\n",
    "            append = False\n",
    "            break\n",
    "\n",
    "        uniq_dicts[col][retrived] = 0\n",
    "\n",
    "    if append:\n",
    "        app_articles.append(article)\n",
    "\n",
    "save_jsonb(app_articles, non_duplicate_folder / \"deduplicated.jsonb\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_by_cat = {col:sum(uniq_dicts[col].values()) for col in UNIQ_COLS}\n",
    "print(sum_by_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from preprocess_utils import load_jsonb, save_jsonb\n",
    "non_duplicate_folder = Path(\"no_duplicates\")\n",
    "output_folder = Path(\"../final_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1628645/1628645 [01:32<00:00, 17519.69it/s]\n",
      "100%|██████████| 1383298/1383298 [01:00<00:00, 22815.76it/s]\n",
      "100%|██████████| 122056/122056 [00:06<00:00, 20281.94it/s]\n",
      "100%|██████████| 122056/122056 [00:06<00:00, 19594.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create splits 85/7.5/7.5 by date\n",
    "from datetime import date\n",
    "import random\n",
    "servers = [f for f in non_duplicate_folder.iterdir()]\n",
    "\n",
    "all_articles = (article for f in servers for article in load_jsonb(f))\n",
    "none_articles = (article for article in all_articles if article[\"date\"] is None)\n",
    "articles = (article for article in all_articles if article[\"date\"] is not None)\n",
    "sorted_articles = sorted(articles, key=lambda x: date.fromisoformat(x[\"date\"]))\n",
    "# Randomly insert none articles\n",
    "for none_art in none_articles:\n",
    "    index = random.randint(0, len(sorted_articles))\n",
    "    sorted_articles.insert(index, none_art)\n",
    "\n",
    "train = sorted_articles[:int(len(sorted_articles) * 0.85)]\n",
    "dev = sorted_articles[int(len(sorted_articles) * 0.85):int(len(sorted_articles) * 0.925)]\n",
    "test = sorted_articles[int(len(sorted_articles) * 0.925):]\n",
    "\n",
    "save_jsonb(train, output_folder / \"train.jsonb\", show_progress=True)\n",
    "save_jsonb(dev, output_folder / \"dev.jsonb\", show_progress=True)\n",
    "save_jsonb(test, output_folder / \"test.jsonb\", show_progress=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ef6dd07bac4272f716e725ea8b79349a1e1a5da9c3680ee7af3d80a9646d624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
