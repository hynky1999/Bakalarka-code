{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WandbSource:\n",
    "    project: str\n",
    "    runs: List[str]\n",
    "    split: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DFSource:\n",
    "    name: str\n",
    "    data: pd.DataFrame\n",
    "    runs: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "tasks = [\"server\", \"category\", \"authors_cum_gender\", \"day_of_week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server': [0, 1, 2, 3, 4, 5], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20]}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from human_extract import get_humans_predictions, get_excel_features, get_preds_f1, get_true\n",
    "predictions_humans = get_humans_predictions(Path(\"../HUMAN_EVAL\"), \"True.csv\", get_excel_features( \"../HUMAN_EVAL/True.csv\"))\n",
    "true = {task: get_true(task) for task in tasks}\n",
    "human_f1 = get_preds_f1(predictions_humans, true)\n",
    "# add rows named Average\n",
    "human_f1.loc[\"Human_Average\"] = human_f1.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n"
     ]
    }
   ],
   "source": [
    "# final\n",
    "import pickle\n",
    "import torch\n",
    "predictions_final = {task: pickle.load(open(f\"../predictions/test_human/{task}_predictions.pkl\", \"rb\")) for task in tasks}\n",
    "\n",
    "predictions_final = {task: torch.cat(pred).argmax(dim=1).tolist() for task, pred in predictions_final.items()}\n",
    "\n",
    "final_f1 = get_preds_f1({\"final\": predictions_final}, true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from functools import cache\n",
    "from human_extract import get_f1\n",
    "\n",
    "@cache\n",
    "def get_trivial_baseline_predictions(task, split):\n",
    "    dst = np.array(load_dataset(\"hynky/czech_news_dataset\", split=\"train\")[task])\n",
    "    dst = dst[dst != 0] - 1\n",
    "    most_common = np.bincount(dst).argmax()\n",
    "    test_dst = np.array(load_dataset(\"hynky/czech_news_dataset\", split=split)[task])\n",
    "    test_dst = test_dst[test_dst != 0] - 1\n",
    "    return [most_common] * len(test_dst)\n",
    "\n",
    "\n",
    "def get_trivial_baseline_f1(splits, tasks):\n",
    "    rows = []\n",
    "    for split in splits:\n",
    "        preds = {task: get_trivial_baseline_predictions(task, split) for task in tasks}\n",
    "        true = {task: get_true(task, split=split) for task in tasks}\n",
    "        f1_macro = get_f1(preds, true, split=split)\n",
    "        f1_micro = get_f1(preds, true, split=split, average=\"micro\")\n",
    "        combined_f1 = list(f1_macro.values())\n",
    "        for i,f in enumerate(f1_micro.values()):\n",
    "            combined_f1.insert(i*2+1, f)\n",
    "        rows.append(combined_f1)\n",
    "\n",
    "    index = [f\"{split}_trivial\" for split in splits]\n",
    "    return pd.DataFrame(rows, columns=pd.MultiIndex.from_product([tasks, [f\"{split}/f1_macro\", f\"{split}/f1_micro\"]]), index=index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/kydliceh/.cache/huggingface/datasets/hynky___parquet/hynky--czech_news_dataset-7dfdf4ade67b74c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n",
      "{'server': [0, 1, 2, 3, 4, 5], 'category': [0, 1, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20], 'authors_cum_gender': [0, 1, 2], 'day_of_week': [0, 1, 2, 3, 4, 5, 6]}\n"
     ]
    }
   ],
   "source": [
    "trivial_f1_small = get_trivial_baseline_f1([\"test_small\"], tasks)\n",
    "trivial_f1 = get_trivial_baseline_f1([\"test\"], tasks)\n",
    "trivial_f1_human = get_trivial_baseline_f1([\"test_human\"], tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">server</th>\n",
       "      <th colspan=\"2\" halign=\"left\">category</th>\n",
       "      <th colspan=\"2\" halign=\"left\">authors_cum_gender</th>\n",
       "      <th colspan=\"2\" halign=\"left\">day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>test/f1_macro</th>\n",
       "      <th>test/f1_micro</th>\n",
       "      <th>test/f1_macro</th>\n",
       "      <th>test/f1_micro</th>\n",
       "      <th>test/f1_macro</th>\n",
       "      <th>test/f1_micro</th>\n",
       "      <th>test/f1_macro</th>\n",
       "      <th>test/f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_trivial</th>\n",
       "      <td>0.105289</td>\n",
       "      <td>0.461706</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.378801</td>\n",
       "      <td>0.258317</td>\n",
       "      <td>0.632588</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.167784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    server                ...   day_of_week              \n",
       "             test/f1_macro test/f1_micro  ... test/f1_macro test/f1_micro\n",
       "test_trivial      0.105289      0.461706  ...      0.041051      0.167784\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trivial_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">server</th>\n",
       "      <th colspan=\"2\" halign=\"left\">category</th>\n",
       "      <th colspan=\"2\" halign=\"left\">authors_cum_gender</th>\n",
       "      <th colspan=\"2\" halign=\"left\">day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>test_human/f1_macro</th>\n",
       "      <th>test_human/f1_micro</th>\n",
       "      <th>test_human/f1_macro</th>\n",
       "      <th>test_human/f1_micro</th>\n",
       "      <th>test_human/f1_macro</th>\n",
       "      <th>test_human/f1_micro</th>\n",
       "      <th>test_human/f1_macro</th>\n",
       "      <th>test_human/f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>final</th>\n",
       "      <td>0.712198</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.520437</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.527895</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.283651</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   server  ...         day_of_week\n",
       "      test_human/f1_macro  ... test_human/f1_micro\n",
       "final            0.712198  ...                0.29\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_extract import get_predictions, get_expected\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "gpt_predictions = get_predictions(\"../GPT3/gpt3-results.jsonl\")\n",
    "gpt_expected = get_expected(\"../GPT3/gpt3-results.jsonl\")\n",
    "# compute f1 macro and micro based on preds df and expected df\n",
    "metrics = {}\n",
    "for task in tasks:\n",
    "    metrics[(task, \"test_small/f1_macro\")] = f1_score(gpt_expected[task], gpt_predictions[task], average=\"macro\")\n",
    "    metrics[(task, \"test_small/f1_micro\")] = f1_score(gpt_expected[task], gpt_predictions[task], average=\"micro\")\n",
    "\n",
    "gpt_f1 = pd.DataFrame(metrics, index=[\"gpt3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">authors_cum_gender</th>\n",
       "      <th colspan=\"2\" halign=\"left\">server</th>\n",
       "      <th colspan=\"2\" halign=\"left\">day_of_week</th>\n",
       "      <th colspan=\"2\" halign=\"left\">category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>test_small/f1_macro</th>\n",
       "      <th>test_small/f1_micro</th>\n",
       "      <th>test_small/f1_macro</th>\n",
       "      <th>test_small/f1_micro</th>\n",
       "      <th>test_small/f1_macro</th>\n",
       "      <th>test_small/f1_micro</th>\n",
       "      <th>test_small/f1_macro</th>\n",
       "      <th>test_small/f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt3</th>\n",
       "      <td>0.429163</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.194891</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.447623</td>\n",
       "      <td>0.7521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      authors_cum_gender  ...            category\n",
       "     test_small/f1_macro  ... test_small/f1_micro\n",
       "gpt3            0.429163  ...              0.7521\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "def get_dict_result(run_name, metrics: dict, metric):\n",
    "    query_str = metric\n",
    "\n",
    "    if query_str not in metrics:\n",
    "        query_str += \"_epoch\"\n",
    "\n",
    "    if query_str not in metrics:\n",
    "        print(f\"WARNING: {query_str} not found in {run_name}\")\n",
    "        return None\n",
    "    \n",
    "    return metrics[query_str]\n",
    "\n",
    "def get_df_result(row, metric):\n",
    "    print(row)\n",
    "    return row[metric].iloc[-1]\n",
    "\n",
    "\n",
    "    \n",
    "def get_results(runs: dict, metric):\n",
    "    results = []\n",
    "    for run_name, metrics in runs.items():\n",
    "            result = None\n",
    "            if isinstance(metrics, dict):\n",
    "                result = get_dict_result(run_name, metrics, metric)\n",
    "            elif isinstance(metrics, pd.Series):\n",
    "                result = get_df_result(metrics, metric)\n",
    "            elif metrics is None:\n",
    "                result = np.nan\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown type {type(metrics)}\")\n",
    "            results.append(result)\n",
    "    print(results)\n",
    "    return results\n",
    "\n",
    "def get_project_name(task, ml_type):\n",
    "    proj = \"hynky/{task}-{ml_type}\"\n",
    "    return proj.format(task=task.capitalize(), ml_type=ml_type)\n",
    "\n",
    "\n",
    "def get_wandb_runs(names, project_name):\n",
    "    api = wandb.Api()\n",
    "    filters = [{\"display_name\": name} for name in names]\n",
    "    runs = list(api.runs(project_name, filters={\"$or\": filters}))\n",
    "    runs = {run.display_name: dict(run.summary) for run in runs}\n",
    "    # sort dictoinary by names\n",
    "    if len(runs) != len(names):\n",
    "        print(f\"WARNING: {len(runs)} runs found, but {len(names)} expected for {project_name}\")\n",
    "        missing = set(names) - set(runs.keys())\n",
    "        print(f\"MISSING: {missing}\")\n",
    "    runs = {name: runs.get(name) for name in names}\n",
    "    return runs\n",
    "\n",
    "def get_df_runs(names, df, task):\n",
    "    # return dict with names as keys and rows as values\n",
    "    df_tmp = df[task]\n",
    "    return {name: df_tmp.loc[name].to_dict() for name in names}\n",
    "\n",
    "\n",
    "def get_runs(source, task):\n",
    "     if isinstance(source, WandbSource):\n",
    "         return get_wandb_runs(source.runs, get_project_name(task, source.project))\n",
    "     elif isinstance(source, DFSource):\n",
    "         return get_df_runs(source.runs, source.data, task)\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "metrics_dict = {\n",
    "    \"test/f1_micro\": \"F1-micro\",\n",
    "    \"test/f1_macro\": \"F1-macro\",\n",
    "    \"test_small/f1_micro\": \"F1-micro\",\n",
    "    \"test_small/f1_macro\": \"F1-macro\",\n",
    "    \"test_human/f1_micro\": \"F1-micro\",\n",
    "    \"test_human/f1_macro\": \"F1-macro\",\n",
    "}\n",
    "\n",
    "models_dict = {\n",
    "    \"RobeCzech-Base\": \"R-Base\",\n",
    "    \"RobeCzech-Short\": \"R-Short\",\n",
    "    \"Fernet-Base\": \"F-Base\",\n",
    "    \"Fernet-Short\": \"F-Short\",\n",
    "    \"test_small_trivial\": \"Baseline\",\n",
    "    \"test_trivial\": \"Baseline\",\n",
    "    \"test_human_trivial\": \"Baseline\",\n",
    "    \"Human_Average\": \"Human\",\n",
    "    \"gpt3\": \"GPT-3\",\n",
    "    \"final\": \"Final\",\n",
    "\n",
    "}\n",
    "\n",
    "task_dict = {\n",
    "    \"server\": \"Server\",\n",
    "    \"category\": \"Category\",\n",
    "    \"authors_cum_gender\": \"Gender\",\n",
    "    \"day_of_week\": \"Day of week\",\n",
    "}\n",
    "\n",
    "def create_table(projs, tasks, metrics):\n",
    "    columns = {}\n",
    "    model_names = []\n",
    "    for task in tasks:\n",
    "        task_read = task_dict.get(task, task)\n",
    "        project_runs = [get_runs(proj, task) for proj in projs]\n",
    "        runs = {}\n",
    "        for run in project_runs:\n",
    "            runs = {**runs, **run}\n",
    "        model_names = [models_dict.get(name, name) for name in runs.keys()]\n",
    "        for metric in metrics:\n",
    "            columns[(task_read, metrics_dict[metric])] = get_results(runs, metric)\n",
    "    # do metrics as multiindex\n",
    "    metrics_df = pd.DataFrame(columns)\n",
    "    metrics_df[\"Model\"] = model_names\n",
    "    # set model names as index\n",
    "    return metrics_df.set_index(\"Model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tables = {\n",
    "    \"tuning\":[\n",
    "    ],\n",
    "    \"basic\": [\n",
    "        DFSource(\"Trivial-Baseline\", trivial_f1, [\"test_trivial\"]),\n",
    "        WandbSource(\"ML\", [\"LR-50\", \"LR-200\"], split=\"test\"),\n",
    "        WandbSource(\"Deep-Learning\", [\"RobeCzech-Base\", \"Fernet-Base\", \"RobeCzech-Short\"], split=\"test\"),\n",
    "        WandbSource(\"Deep-Learning\",[\"RobeCzech-Base\", \"Truncate\", \"LM-tune\", \"Grad-12\", \"Grad-24\"], split=\"test\"),\n",
    "        WandbSource(\"Deep-Learning\",[\"Final\"], split=\"test\")\n",
    "    ],\n",
    "    \"short\": [\n",
    "        DFSource(\"Trivial-Baseline\", trivial_f1_small , [\"test_small_trivial\"]),\n",
    "        WandbSource(\"Deep-Learning\", [\"RobeCzech-Base\", \"RobeCzech-Short\", \"Fernet-Short\"], split=\"test_small\"),\n",
    "        DFSource(\"GPT-3\", gpt_f1, [\"gpt3\"]),\n",
    "    ],\n",
    "    \"human\": [\n",
    "        DFSource(\"Trivial-Baseline\", trivial_f1_human , [\"test_human_trivial\"]),\n",
    "        DFSource(\"Human\", human_f1, [\"Human_Average\"]),\n",
    "        DFSource(\"Final\", final_f1, [\"final\"]),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09523809523809525, 0.2960973134072549, 0.7121976609645749]\n",
      "[0.4000000000000001, 0.3333333333333333, 0.8000000000000002]\n",
      "[0.028846153846153844, 0.4255302732421377, 0.5204365381271194]\n",
      "[0.3, 0.6142734085623224, 0.7959183673469388]\n",
      "[0.24203821656050958, 0.5193677455741007, 0.5278945892907205]\n",
      "[0.57, 0.6033333333333334, 0.79]\n",
      "[0.037267080745341616, 0.11789189687403472, 0.2836507511071971]\n",
      "[0.15, 0.12333333333333334, 0.29]\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"test_human/f1_macro\", \"test_human/f1_micro\"]\n",
    "tasks = [\"server\", \"category\", \"authors_cum_gender\", \"day_of_week\"]\n",
    "tb = create_table(tables[\"human\"], tasks, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# convert float to percentage with 2 decimal places\n",
    "def as_latex(tb):\n",
    "    # fillna not working for some reason\n",
    "    # highlight best results in column by bolding\n",
    "    tb = tb.apply(lambda x: x.apply(lambda y: \"\\\\textbf{\" + \"{:.2f}\".format(y*100)  + \"}\" if y == x.max() else \"{:.2f}\".format(y*100)))\n",
    "    tb = tb.replace(np.nan, \"-\", regex=True)\n",
    "    tb = tb.replace(\"nan\", \"-\", regex=True)\n",
    "    return tb.to_latex(escape=False)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/COMP.TMP/kydliceh_8485/ipykernel_1974217/3012119420.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  return tb.to_latex(escape=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10528931487397941, 0.36919441638172473, 0.3727358682336947, 0.6974121332168579, 0.6938974857330322, 0.5948003530502319, 0.687109112739563, 0.7005615234375, 0.6780757904052734, 0.6907496452331543, 0.7103885412216187]\n",
      "[0.46170610211706103, 0.5277577505407354, 0.533787769548404, 0.7819361686706543, 0.7768155336380005, 0.6785491704940796, 0.7731205224990845, 0.7840335369110107, 0.7636330723762512, 0.7769466638565063, 0.792488694190979]\n",
      "[0.021978563942684527, 0.3330021459068112, 0.3277034028310185, 0.5435124635696411, 0.5396564602851868, 0.3655204474925995, 0.5389659404754639, 0.5518217086791992, 0.5192826986312866, 0.5321670770645142, 0.5605653524398804]\n",
      "[0.3788007577229454, 0.7232489799883427, 0.7268797357684088, 0.7966898083686829, 0.7955119609832764, 0.7745652794837952, 0.793726921081543, 0.8013527393341064, 0.7868661284446716, 0.789707601070404, 0.8046920299530029]\n",
      "WARNING: 2 runs found, but 3 expected for hynky/Authors_cum_gender-Deep-Learning\n",
      "MISSING: {'Fernet-Base'}\n",
      "[0.25831715019910156, 0.43624629590607594, 0.4405715709235813, 0.5118262767791748, nan, 0.449695885181427, 0.5035876631736755, 0.5113158226013184, 0.49983102083206177, 0.49751535058021545, 0.5194019675254822]\n",
      "[0.6325883582125401, 0.6914578054257887, 0.6983030899854688, 0.7466524243354797, nan, 0.6994920372962952, 0.7421008944511414, 0.7508556842803955, 0.7382099032402039, 0.7405757308006287, 0.7503873109817505]\n",
      "[0.041050569033169795, 0.1812924688510043, 0.18344647870604264, 0.2943008542060852, 0.2923663854598999, 0.17422907054424286, 0.29518863558769226, 0.2998467683792114, 0.29113665223121643, 0.2935730516910553, 0.29676830768585205]\n",
      "[0.16778364029625745, 0.19624598544930197, 0.19967064298354853, 0.2949056029319763, 0.29340630769729614, 0.19613946974277496, 0.29567575454711914, 0.30002620816230774, 0.2921118140220642, 0.2947008013725281, 0.29686373472213745]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/COMP.TMP/kydliceh_8485/ipykernel_1974217/3012119420.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  return tb.to_latex(escape=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08981102669004482, 0.7842721343040466, 0.7511593103408813, 0.08981102705001831, 0.6729932163405395]\n",
      "[0.3688, 0.8288000226020813, 0.8036999702453613, 0.36880001425743103, 0.7312]\n",
      "[0.0200793948018875, 0.5617374777793884, 0.3788470327854157, 0.3930864930152893, 0.44762313786172636]\n",
      "[0.3351, 0.8065000176429749, 0.7768999934196472, 0.7788000106811523, 0.7520999999999999]\n",
      "WARNING: 2 runs found, but 3 expected for hynky/Authors_cum_gender-Deep-Learning\n",
      "MISSING: {'Fernet-Short'}\n",
      "[0.2663624354509427, 0.5238218903541565, 0.4745028018951416, nan, 0.4291626476848629]\n",
      "[0.6654, 0.7560999989509583, 0.7429999709129333, nan, 0.7028]\n",
      "[0.041430525698651556, 0.2796197533607483, 0.1740679144859314, 0.1768307983875275, 0.19489117748111326]\n",
      "[0.1696, 0.2833000123500824, 0.19820000231266025, 0.19200000166893005, 0.2083]\n",
      "[0.09523809523809525, 0.2960973134072549, 0.7121976609645749]\n",
      "[0.4000000000000001, 0.3333333333333333, 0.8000000000000002]\n",
      "[0.028846153846153844, 0.4255302732421377, 0.5204365381271194]\n",
      "[0.3, 0.6142734085623224, 0.7959183673469388]\n",
      "[0.24203821656050958, 0.5193677455741007, 0.5278945892907205]\n",
      "[0.57, 0.6033333333333334, 0.79]\n",
      "[0.037267080745341616, 0.11789189687403472, 0.2836507511071971]\n",
      "[0.15, 0.12333333333333334, 0.29]\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "Empty DataFrame\n",
      "Columns: MultiIndex([(     'Server', 'F1-macro'),\n",
      "            (     'Server', 'F1-micro'),\n",
      "            (   'Category', 'F1-macro'),\n",
      "            (   'Category', 'F1-micro'),\n",
      "            (     'Gender', 'F1-macro'),\n",
      "            (     'Gender', 'F1-micro'),\n",
      "            ('Day of week', 'F1-macro'),\n",
      "            ('Day of week', 'F1-micro')],\n",
      "           )\n",
      "Index: Float64Index([], dtype='float64', name='Model') \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{Server} & \\multicolumn{2}{l}{Category} & \\multicolumn{2}{l}{Gender} & \\multicolumn{2}{l}{Day of week} \\\\\n",
      "{} &        F1-macro &        F1-micro &        F1-macro &        F1-micro &        F1-macro &        F1-micro &        F1-macro &        F1-micro \\\\\n",
      "Model    &                 &                 &                 &                 &                 &                 &                 &                 \\\\\n",
      "\\midrule\n",
      "Baseline &           10.53 &           46.17 &            2.20 &           37.88 &           25.83 &           63.26 &            4.11 &           16.78 \\\\\n",
      "LR-50    &           36.92 &           52.78 &           33.30 &           72.32 &           43.62 &           69.15 &           18.13 &           19.62 \\\\\n",
      "LR-200   &           37.27 &           53.38 &           32.77 &           72.69 &           44.06 &           69.83 &           18.34 &           19.97 \\\\\n",
      "R-Base   &           69.74 &           78.19 &           54.35 &           79.67 &           51.18 &           74.67 &           29.43 &           29.49 \\\\\n",
      "F-Base   &           69.39 &           77.68 &           53.97 &           79.55 &               - &               - &           29.24 &           29.34 \\\\\n",
      "R-Short  &           59.48 &           67.85 &           36.55 &           77.46 &           44.97 &           69.95 &           17.42 &           19.61 \\\\\n",
      "Truncate &           68.71 &           77.31 &           53.90 &           79.37 &           50.36 &           74.21 &           29.52 &           29.57 \\\\\n",
      "LM-tune  &           70.06 &           78.40 &           55.18 &           80.14 &           51.13 &  \\textbf{75.09} &  \\textbf{29.98} &  \\textbf{30.00} \\\\\n",
      "Grad-12  &           67.81 &           76.36 &           51.93 &           78.69 &           49.98 &           73.82 &           29.11 &           29.21 \\\\\n",
      "Grad-24  &           69.07 &           77.69 &           53.22 &           78.97 &           49.75 &           74.06 &           29.36 &           29.47 \\\\\n",
      "Final    &  \\textbf{71.04} &  \\textbf{79.25} &  \\textbf{56.06} &  \\textbf{80.47} &  \\textbf{51.94} &           75.04 &           29.68 &           29.69 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{Server} & \\multicolumn{2}{l}{Category} & \\multicolumn{2}{l}{Gender} & \\multicolumn{2}{l}{Day of week} \\\\\n",
      "{} &        F1-macro &        F1-micro &        F1-macro &        F1-micro &        F1-macro &        F1-micro &        F1-macro &        F1-micro \\\\\n",
      "Model    &                 &                 &                 &                 &                 &                 &                 &                 \\\\\n",
      "\\midrule\n",
      "Baseline &            8.98 &           36.88 &            2.01 &           33.51 &           26.64 &           66.54 &            4.14 &           16.96 \\\\\n",
      "R-Base   &  \\textbf{78.43} &  \\textbf{82.88} &  \\textbf{56.17} &  \\textbf{80.65} &  \\textbf{52.38} &  \\textbf{75.61} &  \\textbf{27.96} &  \\textbf{28.33} \\\\\n",
      "R-Short  &           75.12 &           80.37 &           37.88 &           77.69 &           47.45 &           74.30 &           17.41 &           19.82 \\\\\n",
      "F-Short  &            8.98 &           36.88 &           39.31 &           77.88 &               - &               - &           17.68 &           19.20 \\\\\n",
      "GPT-3    &           67.30 &           73.12 &           44.76 &           75.21 &           42.92 &           70.28 &           19.49 &           20.83 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{Server} & \\multicolumn{2}{l}{Category} & \\multicolumn{2}{l}{Gender} & \\multicolumn{2}{l}{Day of week} \\\\\n",
      "{} &        F1-macro &        F1-micro &        F1-macro &        F1-micro &        F1-macro &        F1-micro &        F1-macro &        F1-micro \\\\\n",
      "Model    &                 &                 &                 &                 &                 &                 &                 &                 \\\\\n",
      "\\midrule\n",
      "Baseline &            9.52 &           40.00 &            2.88 &           30.00 &           24.20 &           57.00 &            3.73 &           15.00 \\\\\n",
      "Human    &           29.61 &           33.33 &           42.55 &           61.43 &           51.94 &           60.33 &           11.79 &           12.33 \\\\\n",
      "Final    &  \\textbf{71.22} &  \\textbf{80.00} &  \\textbf{52.04} &  \\textbf{79.59} &  \\textbf{52.79} &  \\textbf{79.00} &  \\textbf{28.37} &  \\textbf{29.00} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/COMP.TMP/kydliceh_8485/ipykernel_1974217/3012119420.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  return tb.to_latex(escape=False)\n",
      "/COMP.TMP/kydliceh_8485/ipykernel_1974217/3012119420.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  return tb.to_latex(escape=False)\n"
     ]
    }
   ],
   "source": [
    "tex_tables = []\n",
    "for table in tables:\n",
    "    metrics = [\"f1_macro\", \"f1_micro\"]\n",
    "    if table == \"human\":\n",
    "        metrics = [f\"test_human/{metric}\" for metric in metrics]\n",
    "    elif table == \"short\":\n",
    "        metrics = [f\"test_small/{metric}\" for metric in metrics]\n",
    "    else:\n",
    "        metrics = [f\"test/{metric}\" for metric in metrics]\n",
    "\n",
    "    tb = create_table(tables[table], tasks, metrics)\n",
    "    tex_tables.append(as_latex(tb))\n",
    "\n",
    "for table in tex_tables:\n",
    "    print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
