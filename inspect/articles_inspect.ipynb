{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./venv/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/lnet/aic/personal/kydliceh/Articles_Analysis/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: mosestokenizer in ./venv/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: docopt in ./venv/lib/python3.10/site-packages (from mosestokenizer) (0.6.2)\n",
      "Requirement already satisfied: openfile in ./venv/lib/python3.10/site-packages (from mosestokenizer) (0.0.7)\n",
      "Requirement already satisfied: uctools in ./venv/lib/python3.10/site-packages (from mosestokenizer) (1.3.0)\n",
      "Requirement already satisfied: toolwrapper in ./venv/lib/python3.10/site-packages (from mosestokenizer) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/lnet/aic/personal/kydliceh/Articles_Analysis/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install mosestokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "used_cols = [\"article length\", \"headline length\", \"brief length\", \"num words\", \"avg word length\", \"num of non-alphanumeric\"]\n",
    "plot_cols = 2\n",
    "plot_rows = 3\n",
    "fig_size = (20, 10)\n",
    "\n",
    "\n",
    "def create_hist_plots(df: pd.DataFrame):\n",
    "    fig, axes = plt.subplots(plot_cols, plot_rows, figsize=fig_size)\n",
    "    fig.suptitle(f\"{df.Name} histogram plots\")\n",
    "    for row in range(plot_rows):\n",
    "        for col in range(plot_cols):\n",
    "            ax = axes[col][row]\n",
    "            df[used_cols[col*plot_rows + row]].hist(ax=ax, bins=150, legend=True)\n",
    "\n",
    "\n",
    "def create_whisker_plots(df: pd.DataFrame):\n",
    "    fig, axes = plt.subplots(plot_cols, plot_rows, figsize=fig_size)\n",
    "    fig.suptitle(f\"{df.Name} whisker plots\")\n",
    "    for row in range(plot_rows):\n",
    "        for col in range(plot_cols):\n",
    "            ax = axes[col][row]\n",
    "            df.boxplot(used_cols[col*plot_rows + row],ax=ax)\n",
    "\n",
    "\n",
    "def create_date_plot(df: pd.DataFrame):\n",
    "    fig, axes = plt.subplots(plot_cols, plot_rows, figsize=fig_size)\n",
    "    fig.suptitle(f\"{df.Name} date plots\")\n",
    "    groupby_date = df.groupby(\"date\")\n",
    "    groupby_date[\"url\"].count().plot(ax=axes[0][0], legend=True)\n",
    "    groupby_date[\"article length\"].mean().plot.area(ax=axes[0][1], legend=True)\n",
    "    groupby_date[\"headline length\"].mean().plot.area(ax=axes[0][2], legend=True)\n",
    "    groupby_date[\"brief length\"].mean().plot.area(ax=axes[1][0], legend = True)\n",
    "    groupby_date[\"num words\"].mean().plot.area(ax=axes[1][1], legend = True)\n",
    "    groupby_date[\"avg word length\"].mean().plot.area(ax=axes[1][2], legend = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_exploratory_plots(df):\n",
    "    create_hist_plots(df)\n",
    "    create_whisker_plots(df)\n",
    "    create_date_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from preprocess_utils import num_of_lines, load_jsonb\n",
    "from mosestokenizer import MosesTokenizer\n",
    "moses = MosesTokenizer(\"cz\")\n",
    "toktok = ToktokTokenizer()\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "@functools.cache\n",
    "def create_df(file):\n",
    "    length = num_of_lines(file)\n",
    "    header = [\"url\", \"article length\", \"headline length\", \"brief length\", \"num words\", \"avg word length\", \"num of non-alphanumeric\", \"date\", \"comments_num\"]\n",
    "    l = []\n",
    "    for js in tqdm(load_jsonb(file), total=length):\n",
    "        url = js[\"url\"]\n",
    "        article = js[\"content\"].strip()\n",
    "        brief = js[\"brief\"].strip()\n",
    "        headline = js[\"headline\"].strip()\n",
    "        article_length = len(article)\n",
    "        brief_length = len(brief)\n",
    "        headline_length = len(headline)\n",
    "\n",
    "        #Tok tok is speedy unlike the others\n",
    "        tokenized = toktok.tokenize(article)\n",
    "        num_words = len(tokenized)\n",
    "        avg_word_length = get_average_word_length(tokenized)\n",
    "        non_alpha = count_non_alpha(tokenized)\n",
    "        date = datetime.fromisoformat(js[\"publication_date\"]) if js[\"publication_date\"] != None else None\n",
    "        if date != None and date.tzinfo == None:\n",
    "            date = date.replace(tzinfo=pytz.UTC)\n",
    "        comments_num = js[\"comments_num\"]\n",
    "        l.append([url, article_length, headline_length, brief_length, num_words, avg_word_length, non_alpha, date, comments_num ])\n",
    "    \n",
    "    df = pd.DataFrame(l,columns=header)\n",
    "    df.Name = file.name\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_average_word_length(tokenized_article):\n",
    "    return sum([len(x) for x in tokenized_article])/len(tokenized_article)\n",
    "\n",
    "\n",
    "def count_non_alpha(article):\n",
    "    # Should new line also count ?\n",
    "    return sum([1 for char in article if not char.isalnum() and not char.isspace()])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1009d01262c4dd5ac0ff089042cb76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='mode', options=('explore', 'best_authors'), value='explore'), Drop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "author_folder = Path(\"article_json_author\")\n",
    "possible_files = [None] + [x for x  in author_folder.iterdir() if x.is_file()]\n",
    "modes = [\"explore\", \"best_authors\"]\n",
    "\n",
    "class CachedData:\n",
    "    def __init__(self, file: Path | None):\n",
    "        self.file = file\n",
    "        self.df = None\n",
    "        if file != None:\n",
    "            self.df = create_df(file)\n",
    "\n",
    "    def update(self, file: Path):\n",
    "        if file != self.file and file != None:\n",
    "            self.df = create_df(file)\n",
    "\n",
    "cached_df = CachedData(None)\n",
    "\n",
    "def best_x_authors(file, num):\n",
    "    auths = get_unique_authors(file)\n",
    "    sorted_auths = sorted(auths.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Total authors: {len(sorted_auths)}\")\n",
    "    print(f\"Top {num} authors: \")\n",
    "    for i in range(num):\n",
    "        print(sorted_auths[i])\n",
    "\n",
    "\n",
    "def interact_main(mode, file):\n",
    "    if file == None:\n",
    "        return\n",
    "\n",
    "    if mode == \"best_authors\":\n",
    "        best_x_authors(file, 100)\n",
    "\n",
    "    if mode == \"explore\":\n",
    "        cached_df.update(file)\n",
    "        df = cached_df.df\n",
    "        create_exploratory_plots(df)\n",
    "\n",
    "\n",
    "interactive_plot = interactive(interact_main, mode=modes, file=possible_files)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Přísahá, že nerozdělí národ, a hned ve druhé větě to poruší? Toho nebudu svědkem, vysvětlila Němcová odchod\n",
      "Češi žijí déle a v důchodu tráví přes 24 let. Dnešní dvacátníci mají podle úřadu s prací končit v 67 letech\n",
      "VIDEO: Jestli si to veřejnost přeje, tak klidně rezignuji, řekl Prymula ke schůzce s Faltýnkem v restauraci\n",
      "140 kilometrů v hodině, hlavou napřed. Fernstädtovou čeká skeletonový šampionát na nejrychlejší dráze světa\n",
      "V Británii draží klíč k místnosti, kde zemřel Napoleon. Z paláce na Svaté Heleně ho přivezl voják pro matku\n",
      "Nedostatek toaletního papíru ukázal krizi centrálního plánování. Nejhůře bylo po požáru papíren v roce 1988\n",
      "Choupenitchova matka: Synovy zápasy jsme neviděli, běloruská televize je nevysílala. Modlila jsem se za něj\n",
      "Ahoj, tady Navalnyj, píše kritik Kremlu k první fotce z nemocnice. Dýchá bez přístrojů a občas opustí lůžko\n",
      "Indonéské Borneo přišlo o celou čtvrtinu deštných pralesů za jediný rok. Kvůli palmovému oleji, říká ekolog\n",
      "Nizozemská firma chce po Česku skoro dvě miliardy. Tvrdí, že přišla o peníze investované do obchodů s mákem\n",
      "Nelegálně těžili dřevo na Vysočině. Sedmičlenný gang vydělal miliony, jeho členům hrozí až deset let vězení\n",
      "Uneseného vietnamského politika dopravili do vlasti slovenským vládním speciálem, nepochybují vyšetřovatelé\n",
      "Protidrogovou politiku vlády povede Jarmila Vedralová. ,Nejhorší možná volba,‘ kritizuje ji její předchůdce\n",
      "Fake news o koronaviru sílí, matoucí zprávy od vlády narušují důvěru lidí, říká Vrabel. Nově radí Prymulovi\n",
      "‚Pro většinu je to jedna příležitost za život.‘ Olympijská kvalifikace je pro softbalistky jedinečnou šancí\n",
      "Meteorologové: V pondělí zasáhnou Česko vedra a později i silné bouřky. V úterý skončí výstraha před požáry\n",
      "Hvězdou zlínského festivalu bude syn legendárního Ennia Morriconeho. Přijede i herec ze seriálu Hra o trůny\n",
      "Důstojníci se nechali najmout na dosažení ‚intimních cílů‘ Nečasové. Nebýt jí, zůstali bezúhonní, píše soud\n",
      "U Tišnova vykolejila část rychlíku se 150 cestujícími. Nikomu se nic nestalo, vlaky kvůli nehodě neprojedou\n",
      "'Je to spíš proti fotbalu, než pro fotbal.' Slávistům se videorozhodčí dříve nelíbil, teď o něj sami žádají\n",
      "Proslavila ho role kapitána Kirka ze Star Treku, teď se William Shatner stal nejstarším člověkem ve vesmíru\n",
      "Historik: Role Urválka se probírala v televizi i v tisku. Nemůžeme ale s jistotou říct, že ho Válková znala\n",
      "‚Asi nejhorší úder v životě.‘ Plíšková vybojovala v Římě další semifinále, pomohlo jí i kuriózní ‚prasátko‘\n",
      "Na návštěvě za hokejovou trenérkou Huvarovou: ‚Jednou na mě protihráč zapískal, ale nedala jsem nic najevo‘\n",
      "Firma spojená s vepřínem v Letech má vrátit 13 milionů. Podle bruselských vyšetřovatelů získala dotaci lstí\n",
      "Nevyužívejte syrský vzdušný prostor, varují letoví regulátoři. Případný útok na Sýrii může narušit navigaci\n",
      "Historická na Hodonínsku, manipulační na Chrudimsku. Vykolejené lokomotivy způsobily škodu přes 1,1 milionu\n",
      "Záskok se mění v plnohodnotné angažmá. Southgate bude anglickou reprezentaci trénovat i v příštích 4 letech\n",
      "Náplast na domácí neúspěch. Fišerová na úvod Světového poháru ve slalomu nestačila jen na suverénní Foxovou\n",
      "Austrálii sužuje vlna extrémních veder. Přes den je místy téměř 50 stupňů, kvůli silnému větru hrozí požáry\n",
      "Největší posun paradoxně přineslo Rusko, policie vyčerpala všechny možnosti, říká ke smrti Masaryka žalobce\n",
      "‚Nedochází k porušení.‘ Přečtěte si, proč zemědělský fond vyplácel dotace Agrofertu i přes stopku v Bruselu\n",
      "‚Je to sportovní zázrak.‘ Trpišovský přirovnal postup Slavie k triumfu Ledecké. Na telefonu slavil i Souček\n",
      "‚Zřejmě se na to vykašlal.' Šéfkontrolor Weis čelí kritice poslanců a vyšetřování kvůli nakládání se mzdami\n",
      "‚Silnice by měly více odpouštět.‘ Česku se nedaří snížit počet obětí dopravních nehod, letos jich je už 387\n",
      "Nejsem blázen, kdyby nezaznělo, že vnitro poskytne součinnost, nešla bych do toho, říká Šojdrová k sirotkům\n",
      "Na klimatickou politiku i digitalizaci. Europarlament se dohodl se členskými státy na rozpočtu pro rok 2020\n",
      "Zpátky na ‚místě činu‘. Film o Queen bude mít premiéru ve Wembley, kde odehráli jeden z největších koncertů\n",
      "Za tři minuty se zastřelím, řekl Rudolf Hrušínský. Výtvarník Roman Štětina tak pronikl do vysílání rozhlasu\n",
      "Že by se měl Zeman distancovat od svých spolupracovníků? 'To není otázka na nás,' říká hradní kancléř Mynář\n",
      "Česká televize odvysílá kritizovaný díl Infiltrace s ‚minimálními úpravami‘. Zařadí po něm debatu odborníků\n",
      "Trutnované z Revoluční ulice budou nově bydlet na nábřeží Václava Havla. Zastupitelé posvětili přejmenování\n",
      "Šikanovaná starostka Mikulčic: Přišli mi říct, že mě odvolají, tak jsem odstoupila sama. Nemám to zapotřebí\n",
      "‚Bylo mu řečeno, aby byl shovívavý.‘ Jaká svědectví a důkazy má policie v reklamní větvi kauzy Čapí hnízdo?\n",
      "Slovenští informatici se snaží otevřít státní správu. Je to lepší než sedět v hospodě a stěžovat si, říkají\n",
      "Preiss: Dabing Street jsem nejdřív odmítl a režisérovi napsal sprostou SMS, aby si nemyslel, že jsem suchar\n",
      "Jde o politický folklor, říká k návrhu zdanění církevních restitucí generální sekretář biskupské konference\n",
      "‚Zdaňuje to, co není příjmem.‘ Ústavní stížnost proti zákonu o církevních restitucích podepsalo 42 senátorů\n",
      "Soudobé dějiny se na 300 základních školách začnou učit jinak, faktografie a biflování bude hrát menší roli\n",
      "Vícemistr Evropy z roku 1996 a brankář, který za Spartu vychytal Barcelonu. Petr Kouba slaví 50. narozeniny\n"
     ]
    }
   ],
   "source": [
    "from preprocess_utils import show_outlier_by_percentiles, show_df_lines, show_outliers, pick_indexes\n",
    "# IROZHLAS INSPECTION\n",
    "\n",
    "df = show_outlier_by_percentiles(create_df(possible_files[1]), \"headline length\", 0.99, limit=50)\n",
    "#df = show_outliers(create_df(possible_files[1]), \"headline length\", 60, \"lower\", limit=20, random=False)\n",
    "mod = lambda art : art[\"headline\"]\n",
    "show_df_lines(df, possible_files[1] ,mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = show_outliers(create_df(possible_files[1]), \"headline length\", 60, \"lower\", limit=20, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>article length</th>\n",
       "      <th>brief length</th>\n",
       "      <th>num words</th>\n",
       "      <th>avg word length</th>\n",
       "      <th>num of non-alphanumeric</th>\n",
       "      <th>date</th>\n",
       "      <th>comments_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline length</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 url  article length  brief length  num words  \\\n",
       "headline length                                                 \n",
       "1                  5               5             5          5   \n",
       "2                  9               9             9          9   \n",
       "3                 20              20            20         20   \n",
       "4                 28              28            28         28   \n",
       "5                 39              39            39         39   \n",
       "6                 42              42            42         42   \n",
       "7                 49              49            49         49   \n",
       "8                 58              58            58         58   \n",
       "9                 57              57            57         57   \n",
       "10                67              67            67         67   \n",
       "11                76              76            76         76   \n",
       "12                97              97            97         97   \n",
       "13               101             101           101        101   \n",
       "14                96              96            96         96   \n",
       "15               119             119           119        119   \n",
       "16               105             105           105        105   \n",
       "17               122             122           122        122   \n",
       "18               136             136           136        136   \n",
       "19               170             170           170        170   \n",
       "20               177             177           177        177   \n",
       "110              199             199           199        199   \n",
       "111               15              15            15         15   \n",
       "112               19              19            19         19   \n",
       "113               16              16            16         16   \n",
       "114               13              13            13         13   \n",
       "115               12              12            12         12   \n",
       "116                7               7             7          7   \n",
       "117                7               7             7          7   \n",
       "118                6               6             6          6   \n",
       "119                3               3             3          3   \n",
       "120                3               3             3          3   \n",
       "121                1               1             1          1   \n",
       "122                1               1             1          1   \n",
       "123                2               2             2          2   \n",
       "124                1               1             1          1   \n",
       "125                1               1             1          1   \n",
       "126                1               1             1          1   \n",
       "131                2               2             2          2   \n",
       "132                1               1             1          1   \n",
       "133                1               1             1          1   \n",
       "135                1               1             1          1   \n",
       "\n",
       "                 avg word length  num of non-alphanumeric  date  comments_num  \n",
       "headline length                                                                \n",
       "1                              5                        5     5             0  \n",
       "2                              9                        9     9             0  \n",
       "3                             20                       20    20             0  \n",
       "4                             28                       28    28             0  \n",
       "5                             39                       39    39             0  \n",
       "6                             42                       42    42             0  \n",
       "7                             49                       49    49             0  \n",
       "8                             58                       58    58             0  \n",
       "9                             57                       57    57             0  \n",
       "10                            67                       67    67             0  \n",
       "11                            76                       76    76             0  \n",
       "12                            97                       97    97             0  \n",
       "13                           101                      101   101             0  \n",
       "14                            96                       96    96             0  \n",
       "15                           119                      119   119             0  \n",
       "16                           105                      105   105             0  \n",
       "17                           122                      122   122             0  \n",
       "18                           136                      136   136             0  \n",
       "19                           170                      170   170             0  \n",
       "20                           177                      177   177             0  \n",
       "110                          199                      199   199             0  \n",
       "111                           15                       15    15             0  \n",
       "112                           19                       19    19             0  \n",
       "113                           16                       16    16             0  \n",
       "114                           13                       13    13             0  \n",
       "115                           12                       12    12             0  \n",
       "116                            7                        7     7             0  \n",
       "117                            7                        7     7             0  \n",
       "118                            6                        6     6             0  \n",
       "119                            3                        3     3             0  \n",
       "120                            3                        3     3             0  \n",
       "121                            1                        1     1             0  \n",
       "122                            1                        1     1             0  \n",
       "123                            2                        2     2             0  \n",
       "124                            1                        1     1             0  \n",
       "125                            1                        1     1             0  \n",
       "126                            1                        1     1             0  \n",
       "131                            2                        2     2             0  \n",
       "132                            1                        1     1             0  \n",
       "133                            1                        1     1             0  \n",
       "135                            1                        1     1             0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
